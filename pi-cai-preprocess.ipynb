{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PI-CAI preprocessing on Kaggle (picai_prep)\n",
    "\n",
    "Runs the **official** [picai_prep](https://github.com/DIAGNijmegen/picai_prep) pipeline: **MHA → nnU-Net raw** (resampled T2W/ADC/HBV to shared voxel spacing).\n",
    "\n",
    "**Run order:** 1) Install pip 2) Paths 3) **PREPROCESSING** (the cell that runs `MHA2nnUNetConverter`) 4) View preprocessed images.\n",
    "\n",
    "**Add dataset:** [Prostate Cancer (PI-CAI) Dataset](https://www.kaggle.com/datasets/varshithpsingh/prostate-cancer-pi-cai-dataset). **Output:** set `OUTPUT_ROOT` in the Paths cell (default: `/kaggle/working`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T06:16:41.222541Z",
     "iopub.status.busy": "2026-02-18T06:16:41.222335Z",
     "iopub.status.idle": "2026-02-18T06:16:45.920392Z",
     "shell.execute_reply": "2026-02-18T06:16:45.919693Z",
     "shell.execute_reply.started": "2026-02-18T06:16:41.222520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install official PI-CAI preprocessing\n",
    "!pip install -q picai_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T06:16:45.923325Z",
     "iopub.status.busy": "2026-02-18T06:16:45.922921Z",
     "iopub.status.idle": "2026-02-18T06:16:45.976794Z",
     "shell.execute_reply": "2026-02-18T06:16:45.976076Z",
     "shell.execute_reply.started": "2026-02-18T06:16:45.923289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths — set these for your environment\n",
    "KAGGLE_INPUT = Path(\"/kaggle/input/prostate-cancer-pi-cai-dataset\")  # PI-CAI dataset (add as input)\n",
    "\n",
    "# Where to save preprocessed output (default: Kaggle working so you can Save Version)\n",
    "# For local runs use e.g. Path(\"./picai_preprocessed\")\n",
    "OUTPUT_ROOT = Path(\"/kaggle/working\")\n",
    "\n",
    "FOLDS = [3, 4]\n",
    "\n",
    "# Check dataset is present\n",
    "if not KAGGLE_INPUT.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found at {KAGGLE_INPUT}. \"\n",
    "        \"Add the PI-CAI dataset (e.g. 'Prostate Cancer (PI-CAI) Dataset') to this notebook.\"\n",
    "    )\n",
    "\n",
    "for f in FOLDS:\n",
    "    fold_dir = KAGGLE_INPUT / f\"picai_public_images_fold{f}\"\n",
    "    n = len(list(fold_dir.iterdir())) if fold_dir.exists() else 0\n",
    "    print(f\"fold{f}: {n} patient dirs\" if fold_dir.exists() else f\"fold{f}: MISSING\")\n",
    "\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "print(\"\\nInput:\", KAGGLE_INPUT)\n",
    "print(\"Output:\", OUTPUT_ROOT.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T06:16:45.977907Z",
     "iopub.status.busy": "2026-02-18T06:16:45.977724Z",
     "iopub.status.idle": "2026-02-18T06:16:46.607076Z",
     "shell.execute_reply": "2026-02-18T06:16:46.606474Z",
     "shell.execute_reply.started": "2026-02-18T06:16:45.977889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Diagnostic: show input structure (picai_prep expects patient_id/patient_id_study_id_{t2w,adc,hbv}.mha)\n",
    "sample_fold = KAGGLE_INPUT / \"picai_public_images_fold3\"\n",
    "if sample_fold.exists():\n",
    "    patients = sorted([p.name for p in sample_fold.iterdir() if p.is_dir()])[:3]\n",
    "    print(\"Sample patient dirs:\", patients)\n",
    "    for pid in patients[:1]:\n",
    "        files = [f.name for f in (sample_fold / pid).iterdir()]\n",
    "        print(f\"  {pid}/ files:\", files)\n",
    "    has_all = all(any(m in f.lower() for f in files) for m in [\"_t2w.mha\", \"_adc.mha\", \"_hbv.mha\"])\n",
    "    print(\"  -> OK, structure matches picai_prep (t2w, adc, hbv present)\" if has_all else \"  -> Missing t2w/adc/hbv .mha\")\n",
    "else:\n",
    "    print(\"Fold0 not found. Listing input root:\", list(KAGGLE_INPUT.iterdir())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING — Run this cell\n",
    "\n",
    "**Run the cell below** to convert MHA → nnU-Net raw (resampled T2W/ADC/HBV). Output is saved to `OUTPUT_ROOT` (set in the Paths cell). Then run \"View preprocessed images\" to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T06:16:46.608107Z",
     "iopub.status.busy": "2026-02-18T06:16:46.607914Z",
     "iopub.status.idle": "2026-02-18T07:04:27.024055Z",
     "shell.execute_reply": "2026-02-18T07:04:27.023475Z",
     "shell.execute_reply.started": "2026-02-18T06:16:46.608089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from picai_prep import MHA2nnUNetConverter\n",
    "from picai_prep.examples.mha2nnunet.picai_archive import generate_mha2nnunet_settings\n",
    "\n",
    "for fold in FOLDS:\n",
    "    fold_name = f\"picai_public_images_fold{fold}\"\n",
    "    input_dir = KAGGLE_INPUT / fold_name\n",
    "    if not input_dir.exists():\n",
    "        print(f\"Skip fold {fold}: {input_dir} not found\")\n",
    "        continue\n",
    "\n",
    "    output_dir = OUTPUT_ROOT / f\"nnUNet_raw_data_fold{fold}\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    settings_path = OUTPUT_ROOT / f\"mha2nnunet_settings_fold{fold}.json\"\n",
    "\n",
    "    task_name = f\"Task2201_picai_fold{fold}\"\n",
    "\n",
    "    # 1) Generate settings for this fold\n",
    "    generate_mha2nnunet_settings(\n",
    "        archive_dir=str(input_dir),\n",
    "        output_path=str(settings_path),\n",
    "        annotations_dir=None,  # no lesion masks required for preprocessing\n",
    "        task=task_name,\n",
    "    )\n",
    "\n",
    "    # 2) Remove annotation_path so conversion runs without lesion masks\n",
    "    with open(settings_path) as f:\n",
    "        settings = json.load(f)\n",
    "    for item in settings[\"archive\"]:\n",
    "        item.pop(\"annotation_path\", None)\n",
    "    with open(settings_path, \"w\") as f:\n",
    "        json.dump(settings, f, indent=4)\n",
    "    n_cases = len(settings[\"archive\"])\n",
    "    print(f\"Fold {fold}: {n_cases} cases (no annotations)\")\n",
    "    if n_cases == 0:\n",
    "        print(f\"  WARNING: No cases in archive for fold {fold}. Check input dir: {input_dir}\")\n",
    "        continue\n",
    "\n",
    "    # 3) Create imagesTr so converter can write\n",
    "    (output_dir / task_name / \"imagesTr\").mkdir(parents=True, exist_ok=True)\n",
    "    # 4) Convert MHA → nnU-Net raw\n",
    "    archive = MHA2nnUNetConverter(\n",
    "        scans_dir=str(input_dir),\n",
    "        output_dir=str(output_dir),\n",
    "        mha2nnunet_settings=str(settings_path),\n",
    "        annotations_dir=None,\n",
    "    )\n",
    "    archive.convert()\n",
    "    (output_dir / task_name).mkdir(parents=True, exist_ok=True)\n",
    "    archive.create_dataset_json()\n",
    "\n",
    "    print(f\"Done fold {fold} -> {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:04:27.025327Z",
     "iopub.status.busy": "2026-02-18T07:04:27.025021Z",
     "iopub.status.idle": "2026-02-18T07:04:27.036183Z",
     "shell.execute_reply": "2026-02-18T07:04:27.035508Z",
     "shell.execute_reply.started": "2026-02-18T07:04:27.025303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Show conversion log: FIRST part (errors appear here) and LAST part\n",
    "from pathlib import Path\n",
    "root = OUTPUT_ROOT if 'OUTPUT_ROOT' in globals() else Path(\"/kaggle/working\")\n",
    "logs = sorted(root.glob(\"**/picai_prep_*.log\"))\n",
    "if logs:\n",
    "    with open(logs[-1]) as f:\n",
    "        lines = f.readlines()\n",
    "    print(\"=== First 120 lines (look for 'CASE' and 'Error:' for why conversion failed) ===\")\n",
    "    print(\"\".join(lines[:120]))\n",
    "    print(\"...\")\n",
    "    print(\"=== Last 25 lines ===\")\n",
    "    print(\"\".join(lines[-25:]))\n",
    "else:\n",
    "    print(\"No picai_prep log found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If imagesTr is empty: check the conversion log\n",
    "\n",
    "Run the cell below to see why conversion failed (last 60 lines of the log)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View preprocessed images\n",
    "\n",
    "Load one preprocessed case and display axial slices for T2W, ADC, and HBV side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:04:27.037909Z",
     "iopub.status.busy": "2026-02-18T07:04:27.037652Z",
     "iopub.status.idle": "2026-02-18T07:04:28.162802Z",
     "shell.execute_reply": "2026-02-18T07:04:28.162092Z",
     "shell.execute_reply.started": "2026-02-18T07:04:27.037887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# View preprocessed T2W / ADC / HBV slices (run after preprocessing cells above)\n",
    "try:\n",
    "    import nibabel as nib\n",
    "except ImportError:\n",
    "    !pip install -q nibabel\n",
    "    import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "if 'OUTPUT_ROOT' not in globals():\n",
    "    OUTPUT_ROOT = Path(\"/kaggle/working\")\n",
    "FOLDS = [3, 4]\n",
    "\n",
    "# Find first available preprocessed fold and case\n",
    "case_dir = None\n",
    "base = None\n",
    "for fold in FOLDS:\n",
    "    task_name = f\"Task2201_picai_fold{fold}\"\n",
    "    task_path = OUTPUT_ROOT / f\"nnUNet_raw_data_fold{fold}\" / task_name\n",
    "    if not task_path.exists():\n",
    "        continue\n",
    "    # Option 1: imagesTr/*_0000.nii.gz\n",
    "    images_tr = task_path / \"imagesTr\"\n",
    "    if images_tr.exists():\n",
    "        files_0000 = list(images_tr.glob(\"*_0000.nii.gz\"))\n",
    "        if files_0000:\n",
    "            case_dir = images_tr\n",
    "            base = files_0000[0].name.replace(\"_0000.nii.gz\", \"\")\n",
    "            print(f\"Showing case: {task_name} / imagesTr / {base}\")\n",
    "            break\n",
    "    # Option 2: search anywhere under task_path for *_0000.nii.gz\n",
    "    if case_dir is None:\n",
    "        for nii in task_path.rglob(\"*_0000.nii.gz\"):\n",
    "            case_dir = nii.parent\n",
    "            base = nii.name.replace(\"_0000.nii.gz\", \"\")\n",
    "            print(f\"Showing case: {task_name} / {case_dir.relative_to(task_path)} / {base}\")\n",
    "            break\n",
    "    if case_dir is not None:\n",
    "        break\n",
    "else:\n",
    "    case_dir = None\n",
    "    base = None\n",
    "\n",
    "if case_dir is None or base is None:\n",
    "    print(\"No preprocessed case found.\")\n",
    "    print(\"  -> Run the PREPROCESSING cell above, then re-run this cell.\")\n",
    "    # Debug: show what is inside the task folder\n",
    "    tp = OUTPUT_ROOT / \"nnUNet_raw_data_fold3\" / \"Task2201_picai_fold3\"\n",
    "    if tp.exists():\n",
    "        print(\"  -> Inside Task2201_picai_fold3:\", [x.name for x in tp.iterdir()])\n",
    "        imtr = tp / \"imagesTr\"\n",
    "        if imtr.exists():\n",
    "            files = list(imtr.glob(\"*.nii.gz\"))[:10]\n",
    "            print(\"  -> imagesTr (first 10):\", [f.name for f in files])\n",
    "        else:\n",
    "            print(\"  -> imagesTr/ does not exist (conversion may have failed; check picai_prep_*.log)\")\n",
    "    else:\n",
    "        for p in sorted(OUTPUT_ROOT.iterdir()):\n",
    "            if p.is_dir() and \"nnUNet\" in p.name:\n",
    "                sub = [x.name for x in p.iterdir()][:5]\n",
    "                print(f\"     {p.name}/  {sub}\")\n",
    "else:\n",
    "    # Load the 3 modalities (nnU-Net: 0000=T2W, 0001=ADC, 0002=HBV)\n",
    "    t2w = nib.load(str(case_dir / f\"{base}_0000.nii.gz\")).get_fdata()\n",
    "    adc = nib.load(str(case_dir / f\"{base}_0001.nii.gz\")).get_fdata()\n",
    "    hbv = nib.load(str(case_dir / f\"{base}_0002.nii.gz\")).get_fdata()\n",
    "\n",
    "    # Axial = slice dimension (usually the one with fewest slices in prostate MRI)\n",
    "    slice_axis = np.argmin(t2w.shape)\n",
    "    n_slices = t2w.shape[slice_axis]\n",
    "    slice_idx = n_slices // 2\n",
    "    slices_to_show = [slice_idx - 3, slice_idx, slice_idx + 3]\n",
    "    slices_to_show = [max(0, min(s, n_slices - 1)) for s in slices_to_show]\n",
    "\n",
    "    def take_slice(vol, axis, idx):\n",
    "        if axis == 0:\n",
    "            return vol[idx, :, :]\n",
    "        if axis == 1:\n",
    "            return vol[:, idx, :]\n",
    "        return vol[:, :, idx]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "    mods = [(\"T2W\", t2w), (\"ADC\", adc), (\"HBV\", hbv)]\n",
    "    for col, (name, vol) in enumerate(mods):\n",
    "        for row, si in enumerate(slices_to_show):\n",
    "            ax = axes[row, col]\n",
    "            sl = take_slice(vol, slice_axis, si)\n",
    "            ax.imshow(sl.T, cmap=\"gray\", origin=\"lower\")\n",
    "            ax.set_axis_off()\n",
    "            if row == 0:\n",
    "                ax.set_title(name)\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f\"slice {si}\")\n",
    "    plt.suptitle(\"Preprocessed axial slices (T2W, ADC, HBV)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Zip output for download\n",
    "\n",
    "Kaggle lets you download `/kaggle/working/`. Zipping reduces the number of files if you download manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T07:04:28.165288Z",
     "iopub.status.busy": "2026-02-18T07:04:28.164537Z",
     "iopub.status.idle": "2026-02-18T07:04:28.168310Z",
     "shell.execute_reply": "2026-02-18T07:04:28.167766Z",
     "shell.execute_reply.started": "2026-02-18T07:04:28.165263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Zip each fold's nnU-Net raw data (optional) — uses Python stdlib\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# if 'OUTPUT_ROOT' not in globals(): OUTPUT_ROOT = Path(\".\")\n",
    "\n",
    "# for fold in FOLDS:\n",
    "#     src = OUTPUT_ROOT / f\"nnUNet_raw_data_fold{fold}\"\n",
    "#     if not src.exists():\n",
    "#         continue\n",
    "#     zip_path = OUTPUT_ROOT / f\"nnUNet_raw_data_fold{fold}.zip\"\n",
    "#     shutil.make_archive(str(zip_path).replace(\".zip\", \"\"), \"zip\", OUTPUT_ROOT, src.name)\n",
    "#     print(f\"Created {zip_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Preprocessed data:** `nnUNet_raw_data_fold3/`, `fold4/` under `OUTPUT_ROOT`.\n",
    "- Each contains resampled T2W, ADC, HBV in nnU-Net raw format (4D NIfTI per case).\n",
    "- **To use as input in another notebook:** On Kaggle, set `OUTPUT_ROOT = Path(\"/kaggle/working\")`, run preprocessing, then click **Save Version** (or create a new Dataset from the output). The saved output becomes a dataset you can add as **Input** to any notebook.\n",
    "- Use these paths in your FPN-MIL pipeline (e.g. load NIfTIs and extract 2D slices/patches) or for nnU-Net/picai_baseline training."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11071316,
     "datasetId": 6427300,
     "sourceId": 10721816,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
