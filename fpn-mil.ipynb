{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FPN-MIL training (self-contained)\n",
        "\n",
        "All code in this notebook. No clone, no imports from the GitHub repo.\n",
        "\n",
        "**Input:** Features from the **pi-cai-feature-extraction** notebook (cropped pipeline):\n",
        "- **Patches are cropped** to the prostate ROI (batch crop or on-the-fly with `MASKS_DIR`).\n",
        "- **One slice** (from the 3-channel cropped volume) = **one patch**; **one case** = **one bag**.\n",
        "- Layout: `multi_scale/<case_id>/<case_id>/` with `C4_patch_features.pt`, `C5_patch_features.pt`, `info_patches.h5`.\n",
        "- Labels CSV: `image_id` (= case/bag id), `fold`, and a 0/1 label column (e.g. `cs_pca`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T11:57:00.075509Z",
          "iopub.status.busy": "2026-02-24T11:57:00.074839Z",
          "iopub.status.idle": "2026-02-24T11:57:00.080793Z",
          "shell.execute_reply": "2026-02-24T11:57:00.080029Z",
          "shell.execute_reply.started": "2026-02-24T11:57:00.075475Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Config â€” expects features from pi-cai-feature-extraction (cropped ROI, one patch per slice, one bag per case)\n",
        "from pathlib import Path\n",
        "\n",
        "INPUT_ROOT = Path(\"/kaggle/input/notebooks/sananiroomand/pi-cai-feature-extraction\")\n",
        "FEAT_FOLDER = \"picai_extracted_features\"\n",
        "LABELS_CSV = INPUT_ROOT / \"picai_labels.csv\"\n",
        "LABEL_COL = \"cs_pca\"\n",
        "\n",
        "WORK_DIR = Path(\"/kaggle/working\") if Path(\"/kaggle/working\").exists() else Path(\".\")\n",
        "# Features from pi-cai-feature-extraction output: .../picai_extracted_features/multi_scale/<case_id>/<case_id>/...\n",
        "FEAT_DIR = INPUT_ROOT / FEAT_FOLDER\n",
        "MS_DIR = FEAT_DIR / \"multi_scale\"  # e.g. .../multi_scale/10000_1000000/10000_1000000/info_patches.h5\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 30\n",
        "LR = 5e-5\n",
        "SEED = 42\n",
        "FPN_DIM = 256\n",
        "ENCODER_DIM = 256\n",
        "SCALES = [16, 32, 128]  # used as scale ids; we have 2 levels C4, C5\n",
        "NUM_WORKERS = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T11:57:00.082501Z",
          "iopub.status.busy": "2026-02-24T11:57:00.082115Z",
          "iopub.status.idle": "2026-02-24T11:57:00.111696Z",
          "shell.execute_reply": "2026-02-24T11:57:00.111108Z",
          "shell.execute_reply.started": "2026-02-24T11:57:00.082465Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 342 Val: 177\n",
            "Label dist train: {0: 200, 1: 142}\n"
          ]
        }
      ],
      "source": [
        "# Load labels and prepare train/val split (features read from input path)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "if not MS_DIR.exists():\n",
        "    raise FileNotFoundError(f\"Feature dir not found: {MS_DIR}. Add pi-cai-feature-extraction output as notebook input.\")\n",
        "\n",
        "df = pd.read_csv(LABELS_CSV)\n",
        "if \"patient_id\" not in df.columns:\n",
        "    c = \"image_id\" if \"image_id\" in df.columns else (\"case_id\" if \"case_id\" in df.columns else df.columns[0])\n",
        "    df[\"patient_id\"] = df[c].astype(str)\n",
        "if \"image_id\" not in df.columns:\n",
        "    df[\"image_id\"] = df[\"patient_id\"].astype(str)\n",
        "df[\"patient_id\"] = df[\"patient_id\"].astype(str)\n",
        "df[\"image_id\"] = df[\"image_id\"].astype(str)\n",
        "\n",
        "df[LABEL_COL] = (pd.to_numeric(df[LABEL_COL], errors=\"coerce\").fillna(0) > 0.5).astype(int)\n",
        "\n",
        "if \"split\" not in df.columns:\n",
        "    if \"fold\" in df.columns:\n",
        "        df[\"split\"] = df[\"fold\"].map(lambda f: \"training\" if f in (0, 1) else \"test\")\n",
        "    else:\n",
        "        tr_idx, te_idx = train_test_split(df.index, test_size=0.2, stratify=df[LABEL_COL], random_state=SEED)\n",
        "        df[\"split\"] = \"test\"\n",
        "        df.loc[tr_idx, \"split\"] = \"training\"\n",
        "\n",
        "CSV_PATH = WORK_DIR / \"labels_with_split.csv\"\n",
        "df.to_csv(CSV_PATH, index=False)\n",
        "train_df = df[df[\"split\"] == \"training\"].reset_index(drop=True)\n",
        "val_df = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
        "print(\"Train:\", len(train_df), \"Val:\", len(val_df))\n",
        "print(\"Label dist train:\", train_df[LABEL_COL].value_counts().to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T11:57:00.113095Z",
          "iopub.status.busy": "2026-02-24T11:57:00.112848Z",
          "iopub.status.idle": "2026-02-24T11:57:00.127610Z",
          "shell.execute_reply": "2026-02-24T11:57:00.126980Z",
          "shell.execute_reply.started": "2026-02-24T11:57:00.113072Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaders ready.\n"
          ]
        }
      ],
      "source": [
        "# Dataset: load C4, C5 from multi_scale/<case_id>/<case_id>/ (cropped patches, one per slice; case = bag)\n",
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "\n",
        "def load_bag(bag_dir, level=None):\n",
        "    fname = f\"{level}_patch_features.pt\" if level else \"patch_features.pt\"\n",
        "    x = torch.load(os.path.join(bag_dir, fname))\n",
        "    with h5py.File(os.path.join(bag_dir, \"info_patches.h5\"), \"r\") as f:\n",
        "        coords = np.array(f[\"coords\"])\n",
        "    idx = np.lexsort((coords[:, 0], coords[:, 1])) if coords.ndim >= 2 else np.arange(len(x))\n",
        "    return x[idx]\n",
        "\n",
        "class FPNMILDataset(Dataset):\n",
        "    def __init__(self, dataframe, feat_root, label_col):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.feat_root = Path(feat_root)\n",
        "        self.label_col = label_col\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        # Bag = case; features at multi_scale/<case_id>/<case_id>/ (from cropped extraction)\n",
        "        bag_id = str(row[\"image_id\"])\n",
        "        bag_dir = self.feat_root / bag_id / bag_id\n",
        "        c4 = load_bag(bag_dir, \"C4\")\n",
        "        c5 = load_bag(bag_dir, \"C5\")\n",
        "        y = torch.tensor(row[self.label_col], dtype=torch.float32)\n",
        "        return {\"x\": [c4, c5], \"y\": y}\n",
        "\n",
        "def collate(batch):\n",
        "    # Bags have different N; pad to max N per scale and pass mask\n",
        "    x_out, mask_out = [], []\n",
        "    for i in range(2):\n",
        "        tensors = [b[\"x\"][i] for b in batch]\n",
        "        max_n = max(t.size(0) for t in tensors)\n",
        "        C, H, W = tensors[0].shape[1], tensors[0].shape[2], tensors[0].shape[3]\n",
        "        padded = torch.zeros(len(batch), max_n, C, H, W, dtype=tensors[0].dtype)\n",
        "        mask = torch.zeros(len(batch), max_n, dtype=torch.float32)\n",
        "        for b_idx, t in enumerate(tensors):\n",
        "            n = t.size(0)\n",
        "            padded[b_idx, :n] = t\n",
        "            mask[b_idx, :n] = 1.0\n",
        "        x_out.append(padded)\n",
        "        mask_out.append(mask)\n",
        "    y = torch.stack([b[\"y\"] for b in batch], dim=0).unsqueeze(1)\n",
        "    return {\"x\": x_out, \"mask\": mask_out, \"y\": y}\n",
        "\n",
        "train_ds = FPNMILDataset(train_df, MS_DIR, LABEL_COL)\n",
        "val_ds = FPNMILDataset(val_df, MS_DIR, LABEL_COL)\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, collate_fn=collate, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate)\n",
        "print(\"Loaders ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T11:57:00.128912Z",
          "iopub.status.busy": "2026-02-24T11:57:00.128648Z",
          "iopub.status.idle": "2026-02-24T11:57:00.186745Z",
          "shell.execute_reply": "2026-02-24T11:57:00.186091Z",
          "shell.execute_reply.started": "2026-02-24T11:57:00.128887Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: 2530310\n"
          ]
        }
      ],
      "source": [
        "# Model: ISAB encoder + gated attention per scale, then gated scale aggregation + classifier\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MAB(nn.Module):\n",
        "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.dim_V = dim_V\n",
        "        self.num_heads = num_heads\n",
        "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
        "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
        "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
        "        self.ln0 = nn.LayerNorm(dim_V) if ln else None\n",
        "        self.ln1 = nn.LayerNorm(dim_V) if ln else None\n",
        "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
        "\n",
        "    def forward(self, Q, K, key_mask=None):\n",
        "        Q, K, V = self.fc_q(Q), self.fc_k(K), self.fc_v(K)\n",
        "        d = self.dim_V // self.num_heads\n",
        "        Q_ = torch.cat(Q.split(d, 2), 0)\n",
        "        K_ = torch.cat(K.split(d, 2), 0)\n",
        "        V_ = torch.cat(V.split(d, 2), 0)\n",
        "        A = Q_.bmm(K_.transpose(1, 2)) / math.sqrt(self.dim_V)\n",
        "        if key_mask is not None:\n",
        "            # A: (B*num_heads, num_inds, N), key_mask: (B, N) -> expand to match A\n",
        "            km = key_mask.unsqueeze(1).expand(-1, A.size(1), -1).unsqueeze(1).expand(-1, self.num_heads, -1, -1).reshape(A.size(0), A.size(1), A.size(2))\n",
        "            A = A.masked_fill(km == 0, -1e9)\n",
        "        A = F.softmax(A, dim=-1)\n",
        "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
        "        O = self.ln0(O) if self.ln0 is not None else O\n",
        "        O = O + F.relu(self.fc_o(O))\n",
        "        O = self.ln1(O) if self.ln1 is not None else O\n",
        "        return O, A\n",
        "\n",
        "class ISAB(nn.Module):\n",
        "    def __init__(self, d_model, d_hidden, num_inds, heads, ln=True):\n",
        "        super().__init__()\n",
        "        self.I = nn.Parameter(torch.Tensor(1, num_inds, d_hidden))\n",
        "        nn.init.xavier_uniform_(self.I)\n",
        "        self.mab0 = MAB(d_hidden, d_model, d_hidden, heads, ln=ln)\n",
        "        self.mab1 = MAB(d_model, d_hidden, d_hidden, heads, ln=ln)\n",
        "\n",
        "    def forward(self, X, key_mask=None):\n",
        "        H, _ = self.mab0(self.I.repeat(X.size(0), 1, 1), X, key_mask=key_mask)\n",
        "        return self.mab1(X, H)[0]\n",
        "\n",
        "class GatedAttn(nn.Module):\n",
        "    def __init__(self, L, D, dropout=0.25):\n",
        "        super().__init__()\n",
        "        self.V = nn.Sequential(nn.Linear(L, D), nn.Tanh(), nn.Dropout(dropout))\n",
        "        self.U = nn.Sequential(nn.Linear(L, D), nn.Sigmoid(), nn.Dropout(dropout))\n",
        "        self.w = nn.Linear(D, 1)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        scores = self.w(self.V(x) * self.U(x))\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask.unsqueeze(-1) == 0, -1e9)\n",
        "        A = F.softmax(scores, dim=1)\n",
        "        return (A.transpose(1, 2) @ x).squeeze(1), A.squeeze(2)\n",
        "\n",
        "class FPNMIL(nn.Module):\n",
        "    def __init__(self, feat_dim=256, encoder_dim=256, num_scales=2, num_inds=20, heads=4, dropout=0.25):\n",
        "        super().__init__()\n",
        "        self.num_scales = num_scales\n",
        "        self.encoders = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                ISAB(feat_dim, encoder_dim, num_inds, heads, ln=True),\n",
        "                ISAB(encoder_dim, encoder_dim, num_inds, heads, ln=True),\n",
        "            ) for _ in range(num_scales)\n",
        "        ])\n",
        "        self.aggregators = nn.ModuleList([GatedAttn(encoder_dim, encoder_dim, dropout) for _ in range(num_scales)])\n",
        "        self.scale_agg = GatedAttn(encoder_dim, encoder_dim, dropout)\n",
        "        self.side_heads = nn.ModuleList([nn.Linear(encoder_dim, 1) for _ in range(num_scales)])\n",
        "        self.head = nn.Sequential(nn.Dropout(dropout), nn.Linear(encoder_dim, 1))\n",
        "\n",
        "    def forward(self, x_list, mask_list=None, deep_sup=True):\n",
        "        scale_embs = []\n",
        "        side_logits = []\n",
        "        for i, x in enumerate(x_list):\n",
        "            # x: (B, N, C, H, W) -> (B, N, C)\n",
        "            if x.dim() == 5:\n",
        "                x = x.mean(dim=(3, 4))\n",
        "            mask = mask_list[i] if mask_list is not None else None\n",
        "            h = self.encoders[i][0](x, key_mask=mask)\n",
        "            h = self.encoders[i][1](h, key_mask=mask)\n",
        "            emb, _ = self.aggregators[i](h, mask=mask)\n",
        "            scale_embs.append(emb)\n",
        "            side_logits.append(self.side_heads[i](emb))\n",
        "        x = torch.stack(scale_embs, dim=1)\n",
        "        emb, _ = self.scale_agg(x)\n",
        "        logits = self.head(emb)\n",
        "        if deep_sup:\n",
        "            return logits, side_logits\n",
        "        return logits\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = FPNMIL(feat_dim=FPN_DIM, encoder_dim=ENCODER_DIM, num_scales=2, num_inds=20, heads=4, dropout=0.25).to(device)\n",
        "print(\"Model:\", sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T11:57:00.188237Z",
          "iopub.status.busy": "2026-02-24T11:57:00.188001Z",
          "iopub.status.idle": "2026-02-24T11:57:00.197705Z",
          "shell.execute_reply": "2026-02-24T11:57:00.196951Z",
          "shell.execute_reply.started": "2026-02-24T11:57:00.188206Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "import random\n",
        "\n",
        "def seed_all(s):\n",
        "    random.seed(s)\n",
        "    np.random.seed(s)\n",
        "    torch.manual_seed(s)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(s)\n",
        "\n",
        "pos = train_df[LABEL_COL].sum()\n",
        "neg = len(train_df) - pos\n",
        "bce_weight = torch.tensor([neg / max(pos, 1)], device=device, dtype=torch.float32)\n",
        "criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
        "\n",
        "def criterion_fn(logits, side_logits, y):\n",
        "    y = y.to(device)\n",
        "    w = torch.where(y > 0.5, bce_weight, torch.ones_like(bce_weight))\n",
        "    loss = (w * criterion(logits, y)).mean()\n",
        "    if side_logits is not None:\n",
        "        for s in side_logits:\n",
        "            loss = loss + 0.5 * (w.squeeze() * criterion(s, y)).mean()\n",
        "    return loss\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "seed_all(SEED)\n",
        "out_dir = WORK_DIR / \"checkpoints\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "best_auc = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T11:57:00.198965Z",
          "iopub.status.busy": "2026-02-24T11:57:00.198669Z",
          "iopub.status.idle": "2026-02-24T11:59:43.135762Z",
          "shell.execute_reply": "2026-02-24T11:59:43.134972Z",
          "shell.execute_reply.started": "2026-02-24T11:57:00.198943Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30 loss=1.6704 val_auc=0.5633 bacc=0.5016 f1=0.0256\n",
            "Epoch 2/30 loss=1.6571 val_auc=0.5775 bacc=0.5077 f1=0.3852\n",
            "Epoch 3/30 loss=1.6168 val_auc=0.5905 bacc=0.5000 f1=0.0000\n",
            "Epoch 4/30 loss=1.6219 val_auc=0.5834 bacc=0.4864 f1=0.3089\n",
            "Epoch 5/30 loss=1.6207 val_auc=0.5887 bacc=0.5296 f1=0.1429\n",
            "Epoch 6/30 loss=1.6109 val_auc=0.5891 bacc=0.5520 f1=0.4762\n",
            "Epoch 7/30 loss=1.6108 val_auc=0.5900 bacc=0.5246 f1=0.1412\n",
            "Epoch 8/30 loss=1.6010 val_auc=0.5888 bacc=0.5314 f1=0.6116\n",
            "Epoch 9/30 loss=1.6024 val_auc=0.5960 bacc=0.5992 f1=0.6321\n",
            "Epoch 10/30 loss=1.5974 val_auc=0.5978 bacc=0.5764 f1=0.5761\n",
            "Epoch 11/30 loss=1.5632 val_auc=0.5952 bacc=0.5345 f1=0.1446\n",
            "Epoch 12/30 loss=1.6044 val_auc=0.5959 bacc=0.6092 f1=0.6224\n",
            "Epoch 13/30 loss=1.6215 val_auc=0.5943 bacc=0.5860 f1=0.6267\n",
            "Epoch 14/30 loss=1.6040 val_auc=0.5969 bacc=0.5767 f1=0.5101\n",
            "Epoch 15/30 loss=1.5914 val_auc=0.5989 bacc=0.6009 f1=0.6280\n",
            "Epoch 16/30 loss=1.5880 val_auc=0.5985 bacc=0.6009 f1=0.6280\n",
            "Epoch 17/30 loss=1.5877 val_auc=0.6012 bacc=0.5992 f1=0.6321\n",
            "Epoch 18/30 loss=1.5909 val_auc=0.6006 bacc=0.5945 f1=0.6042\n",
            "Epoch 19/30 loss=1.5710 val_auc=0.5993 bacc=0.5846 f1=0.5882\n",
            "Epoch 20/30 loss=1.5907 val_auc=0.5977 bacc=0.5909 f1=0.6296\n",
            "Epoch 21/30 loss=1.5647 val_auc=0.5998 bacc=0.6059 f1=0.6231\n",
            "Epoch 22/30 loss=1.5700 val_auc=0.5998 bacc=0.5320 f1=0.5116\n",
            "Epoch 23/30 loss=1.5905 val_auc=0.6008 bacc=0.5371 f1=0.5000\n",
            "Epoch 24/30 loss=1.5805 val_auc=0.6001 bacc=0.6026 f1=0.6238\n",
            "Epoch 25/30 loss=1.5785 val_auc=0.5998 bacc=0.5550 f1=0.5475\n",
            "Epoch 26/30 loss=1.5540 val_auc=0.5998 bacc=0.5879 f1=0.5969\n",
            "Epoch 27/30 loss=1.5786 val_auc=0.6004 bacc=0.5797 f1=0.5851\n",
            "Epoch 28/30 loss=1.5691 val_auc=0.6003 bacc=0.5748 f1=0.5714\n",
            "Epoch 29/30 loss=1.5791 val_auc=0.6003 bacc=0.5814 f1=0.5792\n",
            "Epoch 30/30 loss=1.5816 val_auc=0.6003 bacc=0.5814 f1=0.5792\n",
            "Done. Best checkpoint: /kaggle/working/checkpoints/best.pth\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    all_y, all_p = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            x = [t.to(device) for t in batch[\"x\"]]\n",
        "            mask_list = [m.to(device) for m in batch[\"mask\"]]\n",
        "            y = batch[\"y\"].to(device)\n",
        "            logits, _ = model(x, mask_list=mask_list, deep_sup=True)\n",
        "            all_y.append(y.cpu().numpy())\n",
        "            all_p.append(torch.sigmoid(logits).cpu().numpy())\n",
        "    y = np.vstack(all_y).ravel()\n",
        "    p = np.vstack(all_p).ravel()\n",
        "    pred = (p >= 0.5).astype(int)\n",
        "    auc = roc_auc_score(y, p) if len(np.unique(y)) > 1 else 0.0\n",
        "    return {\"auc\": auc, \"bacc\": balanced_accuracy_score(y, pred), \"f1\": f1_score(y, pred, zero_division=0)}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    for batch in train_loader:\n",
        "        x = [t.to(device) for t in batch[\"x\"]]\n",
        "        mask_list = [m.to(device) for m in batch[\"mask\"]]\n",
        "        y = batch[\"y\"]\n",
        "        optimizer.zero_grad()\n",
        "        logits, side = model(x, mask_list=mask_list, deep_sup=True)\n",
        "        loss = criterion_fn(logits, side, y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        running += loss.item()\n",
        "    scheduler.step()\n",
        "    metrics = evaluate(val_loader)\n",
        "    if metrics[\"auc\"] > best_auc:\n",
        "        best_auc = metrics[\"auc\"]\n",
        "        torch.save({\"model\": model.state_dict(), \"epoch\": epoch}, out_dir / \"best.pth\")\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} loss={running/len(train_loader):.4f} val_auc={metrics['auc']:.4f} bacc={metrics['bacc']:.4f} f1={metrics['f1']:.4f}\")\n",
        "\n",
        "print(\"Done. Best checkpoint:\", out_dir / \"best.pth\")"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "isSourceIdPinned": false,
          "sourceId": 299593384,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31287,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
