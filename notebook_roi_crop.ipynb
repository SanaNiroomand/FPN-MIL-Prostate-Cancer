{
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
    "language_info": { "name": "python", "version": "3.10.0" }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PI-CAI: Crop to prostate ROI using picai_labels masks\n",
        "\n",
        "Uses **whole-gland** masks from [picai_labels](https://github.com/DIAGNijmegen/picai_labels) (`anatomical_delineations/whole_gland/AI/Bosma22b/`) to crop preprocessed nnU-Net volumes to the prostate ROI. Output can be used for FPN-MIL slice/patch extraction.\n",
        "\n",
        "**Inputs:**\n",
        "- Preprocessed NIfTIs from picai_prep (e.g. `nnUNet_raw_data_fold0/.../imagesTr/`).\n",
        "- Prostate masks: `picai_labels/anatomical_delineations/whole_gland/AI/Bosma22b/<case_id>.nii.gz`.\n",
        "\n",
        "**Output:** Cropped T2W, ADC, HBV per case (optional), and a table of bboxes for use in your pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q nibabel SimpleITK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import SimpleITK as sitk\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Paths (set for your environment) ---\n",
        "# Preprocessed data from picai_prep (nnU-Net raw output)\n",
        "PREPROCESSED_ROOT = Path(\"./picai_preprocessed\")  # or /kaggle/input/your-preprocessed-dataset\n",
        "# Folder with prostate masks: anatomical_delineations/whole_gland/AI/Bosma22b/\n",
        "MASKS_DIR = Path(\"./picai_labels/anatomical_delineations/whole_gland/AI/Bosma22b\")\n",
        "# Where to save cropped ROI volumes (optional)\n",
        "OUTPUT_ROI_ROOT = Path(\"/kaggle/working/picai_roi_crops\")\n",
        "\n",
        "FOLD = 0  # which fold to use for demo\n",
        "TASK_NAME = f\"Task2201_picai_fold{FOLD}\"\n",
        "IMAGES_TR = PREPROCESSED_ROOT / f\"nnUNet_raw_data_fold{FOLD}\" / TASK_NAME / \"imagesTr\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get picai_labels masks (if not already present)\n",
        "\n",
        "If `MASKS_DIR` does not exist, we clone the labels repo and use the whole-gland masks. Otherwise skip this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not MASKS_DIR.exists():\n",
        "    !git clone --depth 1 https://github.com/DIAGNijmegen/picai_labels.git\n",
        "    # MASKS_DIR should now be picai_labels/anatomical_delineations/whole_gland/AI/Bosma22b\n",
        "    MASKS_DIR = Path(\"picai_labels/anatomical_delineations/whole_gland/AI/Bosma22b\")\n",
        "    if not MASKS_DIR.exists():\n",
        "        raise FileNotFoundError(f\"Masks not found at {MASKS_DIR}\")\n",
        "    print(\"Masks at:\", MASKS_DIR.resolve())\n",
        "else:\n",
        "    print(\"Using existing masks at:\", MASKS_DIR.resolve())\n",
        "print(\"Number of mask files:\", len(list(MASKS_DIR.glob(\"*.nii.gz\"))) if MASKS_DIR.exists() else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resample mask to volume grid and crop to ROI\n",
        "\n",
        "For each case we load the three modalities (T2W, ADC, HBV), load the prostate mask, resample the mask to the volume grid, compute the 3D bounding box, and crop all three to the ROI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resample_mask_to_volume(mask_sitk: sitk.Image, ref_sitk: sitk.Image) -> sitk.Image:\n",
        "    \"\"\"Resample mask to the same grid as the reference volume (identity transform).\"\"\"\n",
        "    identity = sitk.Transform(3, sitk.sitkIdentity)\n",
        "    return sitk.Resample(mask_sitk, ref_sitk, identity, sitk.sitkNearestNeighbor, 0.0, mask_sitk.GetPixelID())\n",
        "\n",
        "def bbox_3d(mask_arr: np.ndarray, margin: int = 0) -> tuple:\n",
        "    \"\"\"Return (zmin, zmax, ymin, ymax, xmin, xmax) with optional margin.\"\"\"\n",
        "    inds = np.where(mask_arr > 0)\n",
        "    if len(inds[0]) == 0:\n",
        "        return None\n",
        "    zmin, zmax = inds[0].min(), inds[0].max()\n",
        "    ymin, ymax = inds[1].min(), inds[1].max()\n",
        "    xmin, xmax = inds[2].min(), inds[2].max()\n",
        "    nz, ny, nx = mask_arr.shape\n",
        "    zmin = max(0, zmin - margin)\n",
        "    zmax = min(nz - 1, zmax + margin)\n",
        "    ymin = max(0, ymin - margin)\n",
        "    ymax = min(ny - 1, ymax + margin)\n",
        "    xmin = max(0, xmin - margin)\n",
        "    xmax = min(nx - 1, xmax + margin)\n",
        "    return (zmin, zmax + 1, ymin, ymax + 1, xmin, xmax + 1)\n",
        "\n",
        "def crop_volume(arr: np.ndarray, bbox: tuple) -> np.ndarray:\n",
        "    z0, z1, y0, y1, x0, x1 = bbox\n",
        "    return arr[z0:z1, y0:y1, x0:x1].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_one_case(case_id: str, images_tr: Path, masks_dir: Path, output_root: Path, margin: int = 2, save_crops: bool = True) -> dict:\n",
        "    \"\"\"\n",
        "    Load T2W/ADC/HBV and mask, resample mask, crop to ROI. Returns crop info and optionally saves cropped NIfTIs.\n",
        "    \"\"\"\n",
        "    t2w_path = images_tr / f\"{case_id}_0000.nii.gz\"\n",
        "    adc_path = images_tr / f\"{case_id}_0001.nii.gz\"\n",
        "    hbv_path = images_tr / f\"{case_id}_0002.nii.gz\"\n",
        "    mask_path = masks_dir / f\"{case_id}.nii.gz\"\n",
        "    if not t2w_path.exists() or not mask_path.exists():\n",
        "        return None\n",
        "\n",
        "    # Load with SimpleITK for resampling\n",
        "    t2w_sitk = sitk.ReadImage(str(t2w_path))\n",
        "    mask_sitk = sitk.ReadImage(str(mask_path))\n",
        "    mask_resampled = resample_mask_to_volume(mask_sitk, t2w_sitk)\n",
        "    mask_arr = sitk.GetArrayFromImage(mask_resampled)\n",
        "\n",
        "    bbox = bbox_3d(mask_arr, margin=margin)\n",
        "    if bbox is None:\n",
        "        return None\n",
        "\n",
        "    t2w_arr = sitk.GetArrayFromImage(t2w_sitk)\n",
        "    t2w_crop = crop_volume(t2w_arr, bbox)\n",
        "    adc_crop = crop_volume(sitk.GetArrayFromImage(sitk.ReadImage(str(adc_path))), bbox) if adc_path.exists() else None\n",
        "    hbv_crop = crop_volume(sitk.GetArrayFromImage(sitk.ReadImage(str(hbv_path))), bbox) if hbv_path.exists() else None\n",
        "\n",
        "    out_info = {\"case_id\": case_id, \"bbox\": bbox, \"shape": t2w_crop.shape, \"t2w_crop\": t2w_crop, \"adc_crop\": adc_crop, \"hbv_crop\": hbv_crop}\n",
        "\n",
        "    if save_crops and output_root:\n",
        "        out_dir = output_root / case_id\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        for name, arr in [(\"t2w\", t2w_crop), (\"adc\", adc_crop), (\"hbv\", hbv_crop)]:\n",
        "            if arr is not None:\n",
        "                img = nib.Nifti1Image(arr.astype(np.float32), np.eye(4))\n",
        "                nib.save(img, out_dir / f\"{name}.nii.gz\")\n",
        "        out_info[\"out_dir\"] = str(out_dir)\n",
        "    return out_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run ROI crop for one case (demo) and visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_ROI_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Find first case that has both preprocessed images and a mask\n",
        "case_id = None\n",
        "if IMAGES_TR.exists():\n",
        "    for p in sorted(IMAGES_TR.glob(\"*_0000.nii.gz\")):\n",
        "        cid = p.name.replace(\"_0000.nii.gz\", \"\")\n",
        "        if (MASKS_DIR / f\"{cid}.nii.gz\").exists():\n",
        "            case_id = cid\n",
        "            break\n",
        "\n",
        "result = None\n",
        "if case_id is None:\n",
        "    print(\"No case found with both preprocessed data and mask. Check PREPROCESSED_ROOT and MASKS_DIR.\")\n",
        "else:\n",
        "    print(\"Processing case:\", case_id)\n",
        "    result = process_one_case(case_id, IMAGES_TR, MASKS_DIR, OUTPUT_ROI_ROOT, margin=2, save_crops=True)\n",
        "    if result is None:\n",
        "        print(\"Failed to process.\")\n",
        "    else:\n",
        "        print(\"Cropped shape:\", result[\"shape\"])\n",
        "        print(\"Saved to:\", result.get(\"out_dir\", \"N/A\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize: middle slice of cropped T2W\n",
        "if case_id and result is not None and result.get(\"t2w_crop\") is not None:\n",
        "    vol = result[\"t2w_crop\"]\n",
        "    slice_axis = np.argmin(vol.shape)\n",
        "    mid = vol.shape[slice_axis] // 2\n",
        "    if slice_axis == 0:\n",
        "        sl = vol[mid, :, :]\n",
        "    elif slice_axis == 1:\n",
        "        sl = vol[:, mid, :]\n",
        "    else:\n",
        "        sl = vol[:, :, mid]\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "    ax.imshow(sl.T, cmap=\"gray\", origin=\"lower\")\n",
        "    ax.set_title(f\"ROI crop â€“ {case_id} (middle slice)\")\n",
        "    ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch: crop all cases that have a mask\n",
        "\n",
        "Run this to process every case in this fold that has both preprocessed images and a whole-gland mask. Cropped volumes are saved under `OUTPUT_ROI_ROOT/<case_id>/t2w.nii.gz`, `adc.nii.gz`, `hbv.nii.gz`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not IMAGES_TR.exists():\n",
        "    print(\"IMAGES_TR not found. Run picai_prep first.\")\n",
        "else:\n",
        "    case_ids = sorted([p.name.replace(\"_0000.nii.gz\", \"\") for p in IMAGES_TR.glob(\"*_0000.nii.gz\")])\n",
        "    mask_ids = {p.stem.replace(\".nii\", \"\") for p in MASKS_DIR.glob(\"*.nii.gz\")}\n",
        "    to_process = [c for c in case_ids if c in mask_ids]\n",
        "    print(f\"Cases with preprocessed data: {len(case_ids)}\")\n",
        "    print(f\"Cases with mask: {len(mask_ids)}\")\n",
        "    print(f\"Cases to crop (intersection): {len(to_process)}\")\n",
        "    results_list = []\n",
        "    for i, cid in enumerate(to_process):\n",
        "        r = process_one_case(cid, IMAGES_TR, MASKS_DIR, OUTPUT_ROI_ROOT, margin=2, save_crops=True)\n",
        "        if r is not None:\n",
        "            results_list.append({\"case_id\": cid, \"shape\": r[\"shape\"], \"bbox\": r[\"bbox\"]})\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print(f\"Processed {i + 1}/{len(to_process)}\")\n",
        "    print(f\"Done. Cropped {len(results_list)} cases to {OUTPUT_ROI_ROOT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps for FPN-MIL\n",
        "\n",
        "- Use the **cropped** volumes under `OUTPUT_ROI_ROOT/<case_id>/` (t2w.nii.gz, adc.nii.gz, hbv.nii.gz) as input to your **slice or patch extractor**.\n",
        "- Extract 2D instances only from these ROI crops, then run backbone+FPN and MIL as in your pipeline.\n",
        "- You can also use the saved **bbox** per case to crop on-the-fly in a dataloader instead of saving cropped NIfTIs."
      ]
    }
  ]
}
