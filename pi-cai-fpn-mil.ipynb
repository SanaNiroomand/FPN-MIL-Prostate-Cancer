{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"kernelVersion","sourceId":299593384}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train FPN-MIL with extracted features (PI-CAI) â€” no imgaug\n\nSame as `kaggle_train_fpn_mil.ipynb` but **does not install imgaug** (avoids NumPy 2.0 issue). The repo's `dataset_concepts` imports imgaug; we stub it so the import succeeds. Offline MIL only uses pre-extracted features, so the stubs are never used.\n\n**On Kaggle:**  \n1. Add as **input** the dataset with `picai_extracted_features/multi_scale/` and `picai_labels.csv`.  \n2. Set `FEAT_INPUT_PATH` in the paths cell.  \n3. Run all cells. Checkpoints under `/kaggle/working`.\n\n**Local:** Set `FEAT_INPUT_PATH` and `DATA_ROOT` as needed.","metadata":{}},{"cell_type":"code","source":"import sys\n\n# ---- imgaug stub (repo imports it even if you don't use augmentations) ----\nclass BoundingBox: \n    pass\n\nclass BoundingBoxesOnImage: \n    pass\n\nclass _BBS:\n    BoundingBox = BoundingBox\n    BoundingBoxesOnImage = BoundingBoxesOnImage\n\nclass _Augmentables:\n    bbs = _BBS()\n\nclass _FakeImgaug:\n    augmentables = _Augmentables()\n\nsys.modules[\"imgaug\"] = _FakeImgaug()\nsys.modules[\"imgaug.augmentables\"] = _Augmentables()\nsys.modules[\"imgaug.augmentables.bbs\"] = _BBS()\n\nprint(\"imgaug stubbed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:03.035745Z","iopub.execute_input":"2026-02-24T11:07:03.035993Z","iopub.status.idle":"2026-02-24T11:07:03.049751Z"}},"outputs":[{"name":"stdout","text":"imgaug stubbed.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import os, sys\nfrom pathlib import Path\n\nREPO_DIR = Path(\"/kaggle/working/Multi-scale-Attention-based-MIL\")\nassert REPO_DIR.exists(), f\"Repo not found at {REPO_DIR}\"\n\n# Make repo importable\nif str(REPO_DIR) not in sys.path:\n    sys.path.insert(0, str(REPO_DIR))\n\nimport main as repo_main\nprint(\"Imported repo_main from:\", repo_main.__file__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:05.096206Z","iopub.execute_input":"2026-02-24T11:07:05.096662Z","iopub.status.idle":"2026-02-24T11:07:19.587562Z","shell.execute_reply.started":"2026-02-24T11:07:05.096631Z","shell.execute_reply":"2026-02-24T11:07:19.586563Z"}},"outputs":[{"name":"stderr","text":"2026-02-24 11:07:14.458176: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771931234.479819     448 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771931234.486605     448 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771931234.504035     448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771931234.504054     448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771931234.504057     448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771931234.504059     448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Imported repo_main from: /kaggle/working/Multi-scale-Attention-based-MIL/main.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import sys\n\n_argv = sys.argv\nsys.argv = [\"\"]          # prevent argparse from reading notebook args\n\nargs = repo_main.config()  # IMPORTANT: this repo's config() takes NO args\n\nsys.argv = _argv\n\nprint(\"Args built. Keys (first 25):\", list(vars(args).keys())[:25])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:24.166123Z","iopub.execute_input":"2026-02-24T11:07:24.166781Z","iopub.status.idle":"2026-02-24T11:07:24.175167Z","shell.execute_reply.started":"2026-02-24T11:07:24.166751Z","shell.execute_reply":"2026-02-24T11:07:24.174516Z"}},"outputs":[{"name":"stdout","text":"Args built. Keys (first 25): ['output_dir', 'data_dir', 'clip_chk_pt_path', 'csv_file', 'feat_dir', 'img_dir', 'train', 'evaluation', 'eval_set', 'img_size', 'dataset', 'data_frac', 'label', 'num_classes', 'n_runs', 'start_run', 'val_split', 'n_folds', 'start_fold', 'mean', 'std', 'model_type', 'arch', 'swin_encoder', 'pretrained_swin_encoder']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"args.train = True\nargs.evaluation = False\nargs.roi_eval = False\n\nargs.dataset = \"PI_CAI\"\nargs.label = \"cs_pca\"\n\nargs.data_dir = \"/kaggle/working\"\nargs.csv_file = \"labels_with_split.csv\"   # use the one that exists in /kaggle/working\nargs.feat_dir = \"picai_extracted_features\"\nargs.feature_extraction = \"offline\"\n\nargs.mil_type = \"instance\"\nargs.pooling_type = \"attention\"\n\nargs.output_dir = \"/kaggle/working/MIL_runs\"\n\n# Optional: make it quick to test\n# args.epochs = 1\n\nprint(\"train:\", args.train)\nprint(\"epochs:\", getattr(args, \"epochs\", None))\nprint(\"csv_file:\", args.csv_file)\nprint(\"feat_dir:\", args.feat_dir)\nprint(\"output_dir:\", args.output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:26.288817Z","iopub.execute_input":"2026-02-24T11:07:26.289293Z","iopub.status.idle":"2026-02-24T11:07:26.294794Z","shell.execute_reply.started":"2026-02-24T11:07:26.289267Z","shell.execute_reply":"2026-02-24T11:07:26.294061Z"}},"outputs":[{"name":"stdout","text":"train: True\nepochs: 9\ncsv_file: labels_with_split.csv\nfeat_dir: picai_extracted_features\noutput_dir: /kaggle/working/MIL_runs\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from pathlib import Path\n\nfeat_root = Path(args.data_dir) / args.feat_dir\nprint(\"feat_root:\", feat_root)\nprint(\"exists:\", feat_root.exists())\n\n# count a known file type quickly\nn = len(list(feat_root.rglob(\"C4_patch_features.pt\")))\nprint(\"Num C4_patch_features.pt under feat_root:\", n)\n\n# show a couple examples\nexamples = list(feat_root.rglob(\"C4_patch_features.pt\"))[:3]\nfor e in examples:\n    print(\"example:\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:30.206140Z","iopub.execute_input":"2026-02-24T11:07:30.206785Z","iopub.status.idle":"2026-02-24T11:07:30.283003Z","shell.execute_reply.started":"2026-02-24T11:07:30.206755Z","shell.execute_reply":"2026-02-24T11:07:30.282285Z"}},"outputs":[{"name":"stdout","text":"feat_root: /kaggle/working/picai_extracted_features\nexists: True\nNum C4_patch_features.pt under feat_root: 519\nexample: /kaggle/working/picai_extracted_features/multi_scale/11371_1001394/11371_1001394/C4_patch_features.pt\nexample: /kaggle/working/picai_extracted_features/multi_scale/10274_1000279/10274_1000279/C4_patch_features.pt\nexample: /kaggle/working/picai_extracted_features/multi_scale/11040_1001060/11040_1001060/C4_patch_features.pt\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"repo_main.main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:32.184361Z","iopub.execute_input":"2026-02-24T11:07:32.184874Z","iopub.status.idle":"2026-02-24T11:07:32.223800Z","shell.execute_reply.started":"2026-02-24T11:07:32.184847Z","shell.execute_reply":"2026-02-24T11:07:32.222997Z"}},"outputs":[{"name":"stdout","text":"\ntorch.cuda.current_device(): 0\n\nUsing device: cuda\noutput_path: /kaggle/working/MIL_runs/MIL_experiments/PI_CAI_data_frac_1.0/cs_pca/offline_feature_extraction/single_scale-patch_size_16/instance/encoder_mlp-dim_256-dropout_0.0/pooling_attention-dropout_0.0-softmax/2026-02-24\ndf shape: (519, 5)\nIndex(['patient_id', 'image_id', 'cs_pca', 'fold', 'split'], dtype='object')\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from utils.generic_utils import seed_all\nfrom MIL.MIL_experiment import do_experiments\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nseed_all(args.seed)\n\ndo_experiments(args, device)\n\n# The repo prints output_path during the run; also print what args contains:\nprint(\"args.output_dir:\", args.output_dir)\nprint(\"args.output_path (if exists):\", getattr(args, \"output_path\", None))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:34.207376Z","iopub.execute_input":"2026-02-24T11:07:34.207946Z","iopub.status.idle":"2026-02-24T11:07:34.218263Z","shell.execute_reply.started":"2026-02-24T11:07:34.207918Z","shell.execute_reply":"2026-02-24T11:07:34.217665Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\ndf shape: (519, 5)\nIndex(['patient_id', 'image_id', 'cs_pca', 'fold', 'split'], dtype='object')\nargs.output_dir: /kaggle/working/MIL_runs\nargs.output_path (if exists): /kaggle/working/MIL_runs/MIL_experiments/PI_CAI_data_frac_1.0/cs_pca/offline_feature_extraction/single_scale-patch_size_16/instance/encoder_mlp-dim_256-dropout_0.0/pooling_attention-dropout_0.0-softmax/2026-02-24\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from pathlib import Path\n\nout_path = Path(getattr(args, \"output_path\", args.output_dir))\nprint(\"Checking out_path:\", out_path)\nprint(\"Exists?\", out_path.exists())\n\nif out_path.exists():\n    # list some files\n    files = sorted([p for p in out_path.rglob(\"*\") if p.is_file()])\n    print(\"Num files under out_path:\", len(files))\n    print(\"First 30 files:\")\n    for p in files[:30]:\n        print(\" -\", p)\n\n    # specifically search for checkpoints\n    ckpts = [p for p in out_path.rglob(\"*.pth\")]\n    print(\"\\nNum .pth checkpoints:\", len(ckpts))\n    for p in ckpts[:10]:\n        print(\" -\", p)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:36.819576Z","iopub.execute_input":"2026-02-24T11:07:36.820508Z","iopub.status.idle":"2026-02-24T11:07:36.827885Z","shell.execute_reply.started":"2026-02-24T11:07:36.820462Z","shell.execute_reply":"2026-02-24T11:07:36.827122Z"}},"outputs":[{"name":"stdout","text":"Checking out_path: /kaggle/working/MIL_runs/MIL_experiments/PI_CAI_data_frac_1.0/cs_pca/offline_feature_extraction/single_scale-patch_size_16/instance/encoder_mlp-dim_256-dropout_0.0/pooling_attention-dropout_0.0-softmax/2026-02-24\nExists? True\nNum files under out_path: 1\nFirst 30 files:\n - /kaggle/working/MIL_runs/MIL_experiments/PI_CAI_data_frac_1.0/cs_pca/offline_feature_extraction/single_scale-patch_size_16/instance/encoder_mlp-dim_256-dropout_0.0/pooling_attention-dropout_0.0-softmax/2026-02-24/args.yaml\n\nNum .pth checkpoints: 0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Quick sanity check: are we accidentally doing 0 work?\nkeys_to_check = [\n    \"train\", \"n_runs\", \"epochs\", \"n_epochs\", \"max_epochs\",\n    \"fold\", \"csv_file\", \"data_dir\", \"feat_dir\",\n    \"feature_extraction\", \"mil_type\", \"pooling_type\",\n    \"output_dir\"\n]\n\nfor k in keys_to_check:\n    if hasattr(args, k):\n        print(f\"{k}: {getattr(args, k)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:38.977452Z","iopub.execute_input":"2026-02-24T11:07:38.977785Z","iopub.status.idle":"2026-02-24T11:07:38.982936Z","shell.execute_reply.started":"2026-02-24T11:07:38.977760Z","shell.execute_reply":"2026-02-24T11:07:38.982037Z"}},"outputs":[{"name":"stdout","text":"train: True\nn_runs: 1\nepochs: 9\ncsv_file: labels_with_split.csv\ndata_dir: /kaggle/working\nfeat_dir: picai_extracted_features\nfeature_extraction: offline\nmil_type: instance\npooling_type: attention\noutput_dir: /kaggle/working/MIL_runs\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from pathlib import Path\nimport glob\n\nfeat_root = Path(args.data_dir) / args.feat_dir\nprint(\"feat_root:\", feat_root)\nprint(\"exists:\", feat_root.exists())\n\n# count patch feature files anywhere under feat_root\npt_files = list(feat_root.rglob(\"C4_patch_features.pt\"))\nprint(\"Num C4_patch_features.pt under feat_root:\", len(pt_files))\n\n# show a few examples\nfor p in pt_files[:5]:\n    print(\"example:\", p)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:07:41.154775Z","iopub.execute_input":"2026-02-24T11:07:41.155261Z","iopub.status.idle":"2026-02-24T11:07:41.197763Z","shell.execute_reply.started":"2026-02-24T11:07:41.155234Z","shell.execute_reply":"2026-02-24T11:07:41.196941Z"}},"outputs":[{"name":"stdout","text":"feat_root: /kaggle/working/picai_extracted_features\nexists: True\nNum C4_patch_features.pt under feat_root: 519\nexample: /kaggle/working/picai_extracted_features/multi_scale/11371_1001394/11371_1001394/C4_patch_features.pt\nexample: /kaggle/working/picai_extracted_features/multi_scale/10274_1000279/10274_1000279/C4_patch_features.pt\nexample: /kaggle/working/picai_extracted_features/multi_scale/11040_1001060/11040_1001060/C4_patch_features.pt\nexample: /kaggle/working/picai_extracted_features/multi_scale/10643_1000659/10643_1000659/C4_patch_features.pt\nexample: /kaggle/working/picai_extracted_features/multi_scale/11342_1001365/11342_1001365/C4_patch_features.pt\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\n\ncsv_path = Path(args.data_dir) / args.csv_file\nprint(\"Loading:\", csv_path)\n\ndf = pd.read_csv(csv_path)\nprint(\"Loaded df shape:\", df.shape)\nprint(\"Columns:\", df.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:11:49.034799Z","iopub.execute_input":"2026-02-24T11:11:49.035083Z","iopub.status.idle":"2026-02-24T11:11:49.043212Z","shell.execute_reply.started":"2026-02-24T11:11:49.035061Z","shell.execute_reply":"2026-02-24T11:11:49.042517Z"}},"outputs":[{"name":"stdout","text":"Loading: /kaggle/working/labels_with_split.csv\nLoaded df shape: (519, 5)\nColumns: ['patient_id', 'image_id', 'cs_pca', 'fold', 'split']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from pathlib import Path\n\n# detect if you have a \"multi_scale\" subdir\nfeat_root = Path(args.data_dir) / args.feat_dir\nms = feat_root / \"multi_scale\"\nprint(\"multi_scale exists:\", ms.exists(), \"-\", ms)\n\n# use multi_scale if present\nbase = ms if ms.exists() else feat_root\n\n# check how many CSV ids have a matching feature file\nmissing = []\nfound = 0\n\nfor img_id in df[\"image_id\"].astype(str).tolist()[:200]:  # check first 200\n    f = base / img_id / img_id / \"C4_patch_features.pt\"\n    if f.exists():\n        found += 1\n    else:\n        missing.append(img_id)\n\nprint(\"Checked 200 image_ids\")\nprint(\"Found:\", found)\nprint(\"Missing:\", len(missing))\nprint(\"First 10 missing:\", missing[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:11:50.983300Z","iopub.execute_input":"2026-02-24T11:11:50.983773Z","iopub.status.idle":"2026-02-24T11:11:50.995777Z","shell.execute_reply.started":"2026-02-24T11:11:50.983746Z","shell.execute_reply":"2026-02-24T11:11:50.995086Z"}},"outputs":[{"name":"stdout","text":"multi_scale exists: True - /kaggle/working/picai_extracted_features/multi_scale\nChecked 200 image_ids\nFound: 200\nMissing: 0\nFirst 10 missing: []\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from pathlib import Path\n\nrun0 = Path(args.output_dir) / \"run_0\"\nprint(\"run0:\", run0, \"exists:\", run0.exists())\n\nif run0.exists():\n    print(\"All files:\", list(run0.rglob(\"*\"))[:50])\n    print(\"Num total files:\", sum(1 for _ in run0.rglob(\"*\")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:11:54.749822Z","iopub.execute_input":"2026-02-24T11:11:54.750541Z","iopub.status.idle":"2026-02-24T11:11:54.756320Z","shell.execute_reply.started":"2026-02-24T11:11:54.750486Z","shell.execute_reply":"2026-02-24T11:11:54.755593Z"}},"outputs":[{"name":"stdout","text":"run0: /kaggle/working/MIL_runs/run_0 exists: True\nAll files: []\nNum total files: 0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import inspect\nimport MIL.MIL_experiment as me\nprint(inspect.getsource(me.do_experiments)[:2000])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:11:55.877411Z","iopub.execute_input":"2026-02-24T11:11:55.878083Z","iopub.status.idle":"2026-02-24T11:11:55.886765Z","shell.execute_reply.started":"2026-02-24T11:11:55.878055Z","shell.execute_reply":"2026-02-24T11:11:55.886131Z"}},"outputs":[{"name":"stdout","text":"def do_experiments(args, device):\n        \n    args.n_class = 1 # Binary classification setup (single output neuron)\n        \n    # Define class labels based on selected task\n    if args.label.lower() == 'mass':\n        class0 = 'not_mass'\n        class1 = 'mass'\n    elif args.label.lower() == 'suspicious_calcification':\n        class0 = 'not_calcification'\n        class1 = 'calcification'   \n\n    # FALLBACK_CLASS_NAMES\n\n    if 'class0' not in locals() or 'class1' not in locals():\n\n        class0 = 'not_cs_pca'\n\n        class1 = 'cs_pca'\n\n\n    label_dict = {class0: 0, class1: 1}\n\n    ############################ Data Setup ############################\n    args.data_dir = Path(args.data_dir)\n    \n    args.df = pd.read_csv(args.data_dir / args.csv_file)\n    args.df = args.df.fillna(0)\n    \n    print(f\"df shape: {args.df.shape}\")\n    print(args.df.columns)\n\n    # Split data into dev (train+val) and test sets\n    dev_df = args.df[args.df['split'].isin([\"train\", \"val\"])].reset_index(drop=True)\n    test_df = args.df[args.df['split'] == \"test\"].reset_index(drop=True)\n\n    # reduce dataset size for debugging/experiments if desired\n    if args.data_frac < 1.0:\n        dev_df = dev_df.sample(frac=args.data_frac, random_state=1, ignore_index=True) \n\n    # repeated k runs using fixed data splits \n    if args.eval_scheme == 'kruns_train+val+test': \n\n        # split development set into training and validation sets\n        train_df, val_df = stratified_train_val_split(dev_df, 0.2, args = args)\n\n        # initialize results dictionary based on model type\n        if args.multi_scale_model is not None: \n\n            # track results for each scale if required by model configuration\n            if (args.type_scale_aggregator in ['concatenation', 'gated-attention'] and args.deep_supervision) or args.type_scale_aggregator in ['max_p', 'mean_p']:  \n                all_val_results = {scale: {'f1': [], 'bacc': [], 'auc_roc': []} for scale in args.scales}\n                all_test_results = \n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from pathlib import Path\n\nfile_path = Path(\"/kaggle/working/Multi-scale-Attention-based-MIL/MIL/MIL_experiment.py\")\n\ntext = file_path.read_text()\n\ntext = text.replace(\n    \"dev_df = args.df[args.df['split'] == \\\"training\\\"].reset_index(drop=True)\",\n    \"dev_df = args.df[args.df['split'].isin([\\\"train\\\", \\\"val\\\"])].reset_index(drop=True)\"\n)\n\nfile_path.write_text(text)\n\nprint(\"Updated MIL_experiment.py\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T11:11:59.070905Z","iopub.execute_input":"2026-02-24T11:11:59.071572Z","iopub.status.idle":"2026-02-24T11:11:59.077166Z","shell.execute_reply.started":"2026-02-24T11:11:59.071546Z","shell.execute_reply":"2026-02-24T11:11:59.076227Z"}},"outputs":[{"name":"stdout","text":"Updated MIL_experiment.py\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}