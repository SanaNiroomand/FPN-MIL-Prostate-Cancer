{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kaggle: Offline feature extraction (PI-CAI preprocessed)\n",
        "\n",
        "1. **Add input:** Two preprocessed datasets: one with folds 0,1,2 (e.g. pi-cai-preprocess) and one with folds 3,4 (e.g. pi-cai-preprocess-2). Each has `nnUNet_raw_data_fold<N>/.../imagesTr/`.\n",
        "2. **Optional:** Add the PI-CAI dataset with `Metadata(for ISUP).csv` to get real labels; otherwise labels are built from the case list only (cs_pca=0).\n",
        "3. **Set** `PREPROCESSED_ROOTS` in the paths cell to your two input paths (folds 0,1,2 and 3,4).\n",
        "4. **Crop (optional):** Run \"Batch crop all cases\" to save cropped T2W/ADC/HBV to `CROPPED_ROOT`; otherwise extraction crops on the fly when `MASKS_DIR` is set.\n",
        "5. Run extraction. Features are written to `FEAT_DIR`. **Each slice** (one 2D slice from the 3 modalities) = **one patch**; **each case** = **one bag** for FPN-MIL.\n",
        "\n",
        "**Prostate crop:** Clone picai_labels; set `MASKS_DIR` to Bosma22b. Then either run \"Batch crop all cases\" and use `CROPPED_ROOT` for extraction, or run extraction with per-fold roots from CSV + `MASKS_DIR` (crop on the fly)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T19:20:28.732659Z",
          "iopub.status.busy": "2026-02-24T19:20:28.732063Z",
          "iopub.status.idle": "2026-02-24T19:20:33.123906Z",
          "shell.execute_reply": "2026-02-24T19:20:33.122934Z",
          "shell.execute_reply.started": "2026-02-24T19:20:28.732627Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -q SimpleITK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone picai_labels for prostate whole-gland masks (Option 1: use on Kaggle)\n",
        "import os\n",
        "if not os.path.exists(\"/kaggle/working/picai_labels\"):\n",
        "    !git clone --depth 1 https://github.com/DIAGNijmegen/picai_labels.git /kaggle/working/picai_labels\n",
        "else:\n",
        "    print(\"picai_labels already cloned at /kaggle/working/picai_labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T19:20:33.126060Z",
          "iopub.status.busy": "2026-02-24T19:20:33.125705Z",
          "iopub.status.idle": "2026-02-24T19:20:39.023113Z",
          "shell.execute_reply": "2026-02-24T19:20:39.022113Z",
          "shell.execute_reply.started": "2026-02-24T19:20:33.126021Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_55/2477449120.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mmeta_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mmeta_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mrglob\u001b[0;34m(self, pattern, case_sensitive)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mpattern_parts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase_sensitive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_select_from\u001b[0;34m(self, parent_path, scandir)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0msuccessor_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstarting_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuccessor_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_select_from\u001b[0;34m(self, parent_path, scandir)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# avoid exhausting file descriptors when globbing deep trees.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscandir_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Two preprocessed datasets: (path, list of folds). Process folds 0,1,2 from first and 3,4 from second together.\n",
        "PREPROCESSED_ROOTS = [\n",
        "    (\"/kaggle/input/notebooks/sananiroomand/pi-cai-preprocess\", [0, 1, 2]),\n",
        "    (\"/kaggle/input/notebooks/sananiroomand/pi-cai-preprocess-2\", [3, 4]),\n",
        "]\n",
        "LABELS_CSV_PATH = \"/kaggle/working/picai_labels.csv\"\n",
        "FEAT_DIR = \"/kaggle/working/picai_extracted_features\"\n",
        "# Crop to prostate ROI (whole-gland masks from picai_labels; run clone cell first)\n",
        "MASKS_DIR = \"/kaggle/working/picai_labels/anatomical_delineations/whole_gland/AI/Bosma22b\"   # set to None to skip crop\n",
        "CROP_MARGIN = 2   # voxels around prostate bbox\n",
        "# After \"Batch crop all cases\", use this as input to extraction (optional; else extraction crops on the fly)\n",
        "CROPPED_ROOT = \"/kaggle/working/picai_roi_crops\"\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "case_to_fold = {}\n",
        "fold_to_root = {}\n",
        "for root_path, folds in PREPROCESSED_ROOTS:\n",
        "    root = Path(root_path)\n",
        "    if not root.exists():\n",
        "        print(f\"WARNING: Preprocessed root not found (skipped): {root_path}. Add this dataset as input for folds {folds}.\")\n",
        "        continue\n",
        "    for fold in folds:\n",
        "        fold_to_root[fold] = root\n",
        "        images_tr = root / f\"nnUNet_raw_data_fold{fold}\" / f\"Task2201_picai_fold{fold}\" / \"imagesTr\"\n",
        "        if not images_tr.exists():\n",
        "            continue\n",
        "        for f in images_tr.glob(\"*_0000.nii.gz\"):\n",
        "            case_id = f.name.replace(\"_0000.nii.gz\", \"\")\n",
        "            case_to_fold[case_id] = fold\n",
        "\n",
        "FOLDS = sorted(fold_to_root.keys())\n",
        "print(\"Discovered folds:\", FOLDS)\n",
        "if len(FOLDS) < 5:\n",
        "    print(\"WARNING: Only folds\", FOLDS, \"found. Add the second preprocessed dataset (folds 3,4) as input to process all 5 folds.\")\n",
        "cases_per_fold = {f: sum(1 for c, fold in case_to_fold.items() if fold == f) for f in FOLDS}\n",
        "print(\"Cases per fold:\", cases_per_fold)\n",
        "if not case_to_fold:\n",
        "    raise FileNotFoundError(\"No *_0000.nii.gz found under any PREPROCESSED_ROOTS. Check paths and folder layout.\")\n",
        "\n",
        "# Try to load PI-CAI metadata for real cs_pca labels\n",
        "# METADATA_PATHS = [\n",
        "#     Path(\"/kaggle/input/prostate-cancer-pi-cai-dataset/Metadata(for ISUP).csv\"),\n",
        "#     Path(\"/kaggle/input/prostate-cancer-pi-cai-dataset/Metadata(for ISUP without lesion info).csv\"),\n",
        "# ]\n",
        "# df = None\n",
        "# for meta_path in METADATA_PATHS:\n",
        "#     if meta_path.exists():\n",
        "#         df_meta = pd.read_csv(meta_path)\n",
        "#         pid_col = next((c for c in df_meta.columns if \"patient\" in c.lower() or c.lower() == \"id\"), df_meta.columns[0])\n",
        "#         isup_col = next((c for c in df_meta.columns if \"isup\" in c.lower()), None)\n",
        "#         study_col = next((c for c in df_meta.columns if \"study\" in c.lower()), None)\n",
        "#         df_meta[\"patient_id\"] = df_meta[pid_col].astype(str)\n",
        "#         df_meta[\"isup\"] = pd.to_numeric(df_meta[isup_col], errors=\"coerce\") if isup_col else 0\n",
        "#         df_meta[\"case_id\"] = df_meta[\"patient_id\"] + \"_\" + df_meta[study_col].astype(str) if study_col else df_meta[\"patient_id\"]\n",
        "#         df_meta[\"cs_pca\"] = (df_meta[\"isup\"] >= 2).astype(int)\n",
        "#         df_meta[\"fold\"] = df_meta[\"case_id\"].map(case_to_fold)\n",
        "#         df = df_meta[df_meta[\"case_id\"].isin(case_to_fold)][[\"patient_id\", \"case_id\", \"cs_pca\", \"fold\"]].drop_duplicates()\n",
        "#         df = df.rename(columns={\"case_id\": \"image_id\"})\n",
        "#         break\n",
        "\n",
        "# if df is None:\n",
        "#     df = pd.DataFrame([\n",
        "#         {\"patient_id\": cid.split(\"_\")[0], \"image_id\": cid, \"cs_pca\": 0, \"fold\": fold}\n",
        "#         for cid, fold in case_to_fold.items()\n",
        "#     ])\n",
        "#     print(\"No metadata found; using dummy labels (cs_pca=0). Add PI-CAI dataset for real labels.\")\n",
        "# --- Automatically find PI-CAI metadata file ---\n",
        "from pathlib import Path\n",
        "\n",
        "candidates = [\n",
        "    \"Metadata(for ISUP).csv\",\n",
        "    \"Metadata(for ISUP without lesion info).csv\",\n",
        "    \"Metadata with lesion info.csv\",\n",
        "    \"Metadata without lesion info.csv\",\n",
        "]\n",
        "\n",
        "meta_path = None\n",
        "for name in candidates:\n",
        "    hits = list(Path(\"/kaggle/input\").rglob(name))\n",
        "    if hits:\n",
        "        meta_path = hits[0]\n",
        "        break\n",
        "\n",
        "print(\"Using metadata:\", meta_path)\n",
        "df = None\n",
        "\n",
        "if meta_path is not None:\n",
        "    df_meta = pd.read_csv(meta_path)\n",
        "\n",
        "    # identify columns\n",
        "    pid_col = next((c for c in df_meta.columns if \"patient\" in c.lower() or c.lower() == \"id\"), df_meta.columns[0])\n",
        "    isup_col = next((c for c in df_meta.columns if \"isup\" in c.lower()), None)\n",
        "    study_col = next((c for c in df_meta.columns if \"study\" in c.lower()), None)\n",
        "\n",
        "    # build ids\n",
        "    df_meta[\"patient_id\"] = df_meta[pid_col].astype(str)\n",
        "    df_meta[\"isup\"] = pd.to_numeric(df_meta[isup_col], errors=\"coerce\") if isup_col else 0\n",
        "    df_meta[\"case_id\"] = df_meta[\"patient_id\"] + \"_\" + df_meta[study_col].astype(str) if study_col else df_meta[\"patient_id\"]\n",
        "\n",
        "    # label (csPCa proxy from ISUP)\n",
        "    df_meta[\"cs_pca\"] = (df_meta[\"isup\"] >= 2).astype(int)\n",
        "\n",
        "    # map to folds discovered from preprocessed data\n",
        "    df_meta[\"fold\"] = df_meta[\"case_id\"].map(case_to_fold)\n",
        "\n",
        "    # keep only cases that exist in preprocessed set\n",
        "    df = (\n",
        "        df_meta[df_meta[\"case_id\"].isin(case_to_fold)]\n",
        "        [[\"patient_id\", \"case_id\", \"cs_pca\", \"fold\"]]\n",
        "        .drop_duplicates()\n",
        "        .rename(columns={\"case_id\": \"image_id\"})\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "# fallback if still None or empty (e.g., ID mismatch)\n",
        "if df is None or len(df) == 0:\n",
        "    df = pd.DataFrame([\n",
        "        {\"patient_id\": cid.split(\"_\")[0], \"image_id\": cid, \"cs_pca\": 0, \"fold\": fold}\n",
        "        for cid, fold in case_to_fold.items()\n",
        "    ])\n",
        "    print(\"WARNING: metadata did not match preprocessed case_ids; using dummy labels (cs_pca=0).\")\n",
        "    # fallback df creation...\n",
        "df[\"preprocessed_root\"] = df[\"fold\"].map(fold_to_root).astype(str)\n",
        "df.to_csv(LABELS_CSV_PATH, index=False)\n",
        "print(f\"Saved {LABELS_CSV_PATH} with {len(df)} rows. Fold counts:\", df[\"fold\"].value_counts().sort_index().to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-02-24T19:20:39.023584Z",
          "iopub.status.idle": "2026-02-24T19:20:39.023821Z",
          "shell.execute_reply": "2026-02-24T19:20:39.023721Z",
          "shell.execute_reply.started": "2026-02-24T19:20:39.023708Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.to_csv(LABELS_CSV_PATH, index=False)\n",
        "print(\"cs_pca value counts (incl NaN):\")\n",
        "print(df[\"cs_pca\"].value_counts(dropna=False))\n",
        "\n",
        "all_zero = (df[\"cs_pca\"] == 0).all()\n",
        "any_one = (df[\"cs_pca\"] == 1).any()\n",
        "print(\"All rows cs_pca==0 ?\", all_zero)\n",
        "print(\"Any cs_pca==1 ?\", any_one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print dimensions of preprocessed volumes (run after paths + labels cell)\n",
        "# Preprocessed slice size: 640×640 (H×W). Each slice is resized to 224×224 for patch extraction.\n",
        "# nnUNet layout: 0000=T2W, 0001=ADC, 0002=HBV. Extractor uses all 3; notebook viz uses T2W only.\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "try:\n",
        "    import SimpleITK as sitk\n",
        "    def _load_nii(path):\n",
        "        return np.asarray(sitk.GetArrayFromImage(sitk.ReadImage(str(path))), dtype=np.float32)\n",
        "except ImportError:\n",
        "    import nibabel as nib\n",
        "    def _load_nii(path):\n",
        "        a = nib.load(str(path)).get_fdata()\n",
        "        return np.transpose(a, (2, 0, 1)).astype(np.float32)\n",
        "\n",
        "MODALITIES = [(\"0000\", \"T2W\"), (\"0001\", \"ADC\"), (\"0002\", \"HBV\")]\n",
        "N_CASES = 10   # number of cases to print dimensions for\n",
        "count = 0\n",
        "for _, row in df.iterrows():\n",
        "    if count >= N_CASES:\n",
        "        break\n",
        "    cid, f = str(row[\"image_id\"]), int(row[\"fold\"])\n",
        "    root = fold_to_root[f]\n",
        "    tr = root / f\"nnUNet_raw_data_fold{f}\" / f\"Task2201_picai_fold{f}\" / \"imagesTr\"\n",
        "    if not (tr / f\"{cid}_0000.nii.gz\").exists():\n",
        "        continue\n",
        "    count += 1\n",
        "    print(f\"Case {cid} (fold {f}):\")\n",
        "    shapes = []\n",
        "    for suffix, name in MODALITIES:\n",
        "        p = tr / f\"{cid}_{suffix}.nii.gz\"\n",
        "        if p.exists():\n",
        "            arr = _load_nii(p)\n",
        "            D, H, W = arr.shape[0], arr.shape[1], arr.shape[2]\n",
        "            print(f\"  {name} (_{suffix}) shape = (D, H, W) = ({D}, {H}, {W})  [slices, height, width]\")\n",
        "            shapes.append((D, H, W))\n",
        "        else:\n",
        "            print(f\"  {name} ({suffix}): not found\")\n",
        "    if len(shapes) == 3:\n",
        "        D, H, W = shapes[0]\n",
        "        print(f\"  Full volume (3 mods stacked): (C, D, H, W) = (3, {D}, {H}, {W})\")\n",
        "    print()\n",
        "if count == 0:\n",
        "    print(\"No case found. Run paths cell and ensure PREPROCESSED_ROOTS have data.\")\n",
        "else:\n",
        "    print(f\"(Feature extraction uses all 3 modalities; notebook visualizations use T2W only. Showed {count} cases.)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize patch extent (one patch per slice)\n",
        "\n",
        "The extractor takes **one patch per slice**: each 2D slice (640×640) is resized/padded to 224×224. The green box shows the full slice (that whole region becomes one patch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-02-24T19:20:39.025045Z",
          "iopub.status.idle": "2026-02-24T19:20:39.025389Z",
          "shell.execute_reply": "2026-02-24T19:20:39.025237Z",
          "shell.execute_reply.started": "2026-02-24T19:20:39.025215Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Visualize patch bounding box for a sample case (run after paths + labels cell)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "PATCH_SIZE = 224   # must match extractor\n",
        "# One patch per slice (full slice resized to 224×224)\n",
        "\n",
        "try:\n",
        "    import SimpleITK as sitk\n",
        "    def _load_nii(path):\n",
        "        return np.asarray(sitk.GetArrayFromImage(sitk.ReadImage(str(path))), dtype=np.float32)\n",
        "except ImportError:\n",
        "    import nibabel as nib\n",
        "    def _load_nii(path):\n",
        "        a = nib.load(str(path)).get_fdata()\n",
        "        return np.transpose(a, (2, 0, 1)).astype(np.float32)\n",
        "\n",
        "case_id, fold = None, None\n",
        "for _, row in df.head(20).iterrows():\n",
        "    cid, f = str(row[\"image_id\"]), int(row[\"fold\"])\n",
        "    root = fold_to_root[f]\n",
        "    tr = root / f\"nnUNet_raw_data_fold{f}\" / f\"Task2201_picai_fold{f}\" / \"imagesTr\"\n",
        "    if (tr / f\"{cid}_0000.nii.gz\").exists():\n",
        "        case_id, fold = cid, f\n",
        "        break\n",
        "if case_id is None:\n",
        "    print(\"No case found under PREPROCESSED_ROOTS. Run paths cell and ensure data exists.\")\n",
        "else:\n",
        "    root = fold_to_root[fold]\n",
        "    tr = root / f\"nnUNet_raw_data_fold{fold}\" / f\"Task2201_picai_fold{fold}\" / \"imagesTr\"\n",
        "    t2w = _load_nii(tr / f\"{case_id}_0000.nii.gz\")  # shape (D, H, W)\n",
        "    n_slices = t2w.shape[0]\n",
        "    H, W = t2w.shape[1], t2w.shape[2]\n",
        "    indices = [max(0, n_slices//2 - 2), n_slices//2 - 1, n_slices//2, min(n_slices-1, n_slices//2 + 1), min(n_slices-1, n_slices//2 + 2)]\n",
        "    indices = sorted(set(indices))[:5]\n",
        "    fig, axes = plt.subplots(1, len(indices), figsize=(4*len(indices), 4))\n",
        "    if len(indices) == 1:\n",
        "        axes = [axes]\n",
        "    for ax, zi in zip(axes, indices):\n",
        "        sl = t2w[zi]  # shape (H, W)\n",
        "        ax.imshow(sl.T, cmap=\"gray\", origin=\"lower\", extent=[0, W, 0, H], aspect=\"equal\")\n",
        "        # One patch per slice: full slice → resized to 224×224\n",
        "        r = plt.Rectangle((0, 0), W, H, fill=False, edgecolor=\"lime\", linewidth=2)\n",
        "        ax.add_patch(r)\n",
        "        ax.set_xlim(0, W)\n",
        "        ax.set_ylim(0, H)\n",
        "        ax.set_title(f\"slice {zi} → one patch\")\n",
        "        ax.set_axis_off()\n",
        "    plt.suptitle(f\"Case {case_id} — one 224×224 patch per slice\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize crop: before (full volume) vs after (prostate ROI)\n",
        "\n",
        "Requires `MASKS_DIR` to be set. Three rows: **Before** = full slice with prostate mask contour (green) and ROI box (cyan); **After** = cropped volume; **Mask** = whole-gland mask for the same slices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch crop all cases to prostate ROI\n",
        "\n",
        "Crop **all** cases (T2W, ADC, HBV) to the prostate bounding box and save to `CROPPED_ROOT` with the same fold layout. Run this once (after paths + clone + df). Then run extraction: **each slice** (one 2D slice from the 3-channel volume) = **one patch**, and **each case** = **one bag** for the FPN-MIL model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch crop all cases: save cropped T2W, ADC, HBV to CROPPED_ROOT (same fold layout)\n",
        "# Run after paths cell and clone; requires MASKS_DIR and df.\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import SimpleITK as sitk\n",
        "except ImportError:\n",
        "    sitk = None\n",
        "\n",
        "def resample_mask_to_ref(mask_path, ref_sitk):\n",
        "    mask = sitk.ReadImage(str(mask_path))\n",
        "    res = sitk.Resample(mask, ref_sitk, sitk.Transform(3, sitk.sitkIdentity), sitk.sitkNearestNeighbor, 0.0)\n",
        "    return np.asarray(sitk.GetArrayFromImage(res))\n",
        "\n",
        "def bbox_3d(mask, margin=0):\n",
        "    inds = np.where(mask > 0)\n",
        "    if len(inds[0]) == 0:\n",
        "        return None\n",
        "    zmin, zmax = inds[0].min() - margin, inds[0].max() + 1 + margin\n",
        "    ymin, ymax = inds[1].min() - margin, inds[1].max() + 1 + margin\n",
        "    xmin, xmax = inds[2].min() - margin, inds[2].max() + 1 + margin\n",
        "    zmin, ymin, xmin = max(0, zmin), max(0, ymin), max(0, xmin)\n",
        "    zmax = min(mask.shape[0], zmax)\n",
        "    ymax = min(mask.shape[1], ymax)\n",
        "    xmax = min(mask.shape[2], xmax)\n",
        "    return (zmin, zmax), (ymin, ymax), (xmin, xmax)\n",
        "\n",
        "out_root = Path(CROPPED_ROOT)\n",
        "masks_dir = Path(MASKS_DIR) if MASKS_DIR else None\n",
        "\n",
        "if masks_dir is None or not masks_dir.exists():\n",
        "    print(\"Set MASKS_DIR (and run clone cell) to batch crop. Skipping.\")\n",
        "elif df is None or df.empty:\n",
        "    print(\"Run paths cell first so df exists. Skipping.\")\n",
        "else:\n",
        "    out_root.mkdir(parents=True, exist_ok=True)\n",
        "    done, skip_no_mask, err = 0, 0, 0\n",
        "    for _, row in df.iterrows():\n",
        "        cid, f = str(row[\"image_id\"]), int(row[\"fold\"])\n",
        "        root = fold_to_root[f]\n",
        "        tr = root / f\"nnUNet_raw_data_fold{f}\" / f\"Task2201_picai_fold{f}\" / \"imagesTr\"\n",
        "        out_tr = out_root / f\"nnUNet_raw_data_fold{f}\" / f\"Task2201_picai_fold{f}\" / \"imagesTr\"\n",
        "        mask_path = masks_dir / f\"{cid}.nii.gz\"\n",
        "        if not (tr / f\"{cid}_0000.nii.gz\").exists():\n",
        "            continue\n",
        "        if not mask_path.exists():\n",
        "            skip_no_mask += 1\n",
        "            continue\n",
        "        out_tr.mkdir(parents=True, exist_ok=True)\n",
        "        if (out_tr / f\"{cid}_0000.nii.gz\").exists():\n",
        "            done += 1\n",
        "            continue\n",
        "        try:\n",
        "            ref = sitk.ReadImage(str(tr / f\"{cid}_0000.nii.gz\"))\n",
        "            t2w = np.asarray(sitk.GetArrayFromImage(ref), dtype=np.float32)\n",
        "            adc = np.asarray(sitk.GetArrayFromImage(sitk.ReadImage(str(tr / f\"{cid}_0001.nii.gz\"))), dtype=np.float32)\n",
        "            hbv = np.asarray(sitk.GetArrayFromImage(sitk.ReadImage(str(tr / f\"{cid}_0002.nii.gz\"))), dtype=np.float32)\n",
        "            mask_arr = resample_mask_to_ref(mask_path, ref)\n",
        "            box = bbox_3d(mask_arr, margin=CROP_MARGIN)\n",
        "            if box is None:\n",
        "                skip_no_mask += 1\n",
        "                continue\n",
        "            (zmin, zmax), (ymin, ymax), (xmin, xmax) = box\n",
        "            t2w_c = t2w[zmin:zmax, ymin:ymax, xmin:xmax]\n",
        "            adc_c = adc[zmin:zmax, ymin:ymax, xmin:xmax]\n",
        "            hbv_c = hbv[zmin:zmax, ymin:ymax, xmin:xmax]\n",
        "            origin = list(ref.GetOrigin())\n",
        "            spacing = ref.GetSpacing()\n",
        "            direction = ref.GetDirection()\n",
        "            origin[0] += xmin * spacing[0]\n",
        "            origin[1] += ymin * spacing[1]\n",
        "            origin[2] += zmin * spacing[2]\n",
        "            for name, arr in [(\"_0000\", t2w_c), (\"_0001\", adc_c), (\"_0002\", hbv_c)]:\n",
        "                img = sitk.GetImageFromArray(arr)\n",
        "                img.SetSpacing(spacing)\n",
        "                img.SetOrigin(origin)\n",
        "                img.SetDirection(direction)\n",
        "                sitk.WriteImage(img, str(out_tr / f\"{cid}{name}.nii.gz\"))\n",
        "            done += 1\n",
        "            if done % 50 == 0:\n",
        "                print(\"Cropped\", done, \"cases...\")\n",
        "        except Exception as e:\n",
        "            err += 1\n",
        "            print(\"Error\", cid, e)\n",
        "    print(f\"Batch crop done. Saved to {out_root}. Cropped: {done}, skipped (no mask): {skip_no_mask}, errors: {err}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show cropped images — all alignments\n",
        "\n",
        "**2 cases × 6 slices** through the cropped stack; **every slice** has the mask contour (green) overlaid so you can verify alignment from top to bottom. Same convention: array `(H,W)` with `[y,x]`, no `.T`. If the green outline follows the prostate on every slice, the crop and mask are aligned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show cropped images (from CROPPED_ROOT if available, else crop in memory). Alignment: same (H,W) [y,x], no .T.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import SimpleITK as sitk\n",
        "except ImportError:\n",
        "    sitk = None\n",
        "\n",
        "def _load_nii(path):\n",
        "    if sitk:\n",
        "        return np.asarray(sitk.GetArrayFromImage(sitk.ReadImage(str(path))), dtype=np.float32)\n",
        "    import nibabel as nib\n",
        "    a = nib.load(str(path)).get_fdata()\n",
        "    return np.transpose(a, (2, 0, 1)).astype(np.float32)\n",
        "\n",
        "def resample_mask_to_ref(mask_path, ref_sitk):\n",
        "    mask = sitk.ReadImage(str(mask_path))\n",
        "    res = sitk.Resample(mask, ref_sitk, sitk.Transform(3, sitk.sitkIdentity), sitk.sitkNearestNeighbor, 0.0)\n",
        "    return np.asarray(sitk.GetArrayFromImage(res))\n",
        "\n",
        "def bbox_3d(mask, margin=0):\n",
        "    inds = np.where(mask > 0)\n",
        "    if len(inds[0]) == 0:\n",
        "        return None\n",
        "    zmin, zmax = inds[0].min() - margin, inds[0].max() + 1 + margin\n",
        "    ymin, ymax = inds[1].min() - margin, inds[1].max() + 1 + margin\n",
        "    xmin, xmax = inds[2].min() - margin, inds[2].max() + 1 + margin\n",
        "    zmin, ymin, xmin = max(0, zmin), max(0, ymin), max(0, xmin)\n",
        "    zmax = min(mask.shape[0], zmax)\n",
        "    ymax = min(mask.shape[1], ymax)\n",
        "    xmax = min(mask.shape[2], xmax)\n",
        "    return (zmin, zmax), (ymin, ymax), (xmin, xmax)\n",
        "\n",
        "cropped_root = Path(CROPPED_ROOT)\n",
        "masks_dir = Path(MASKS_DIR) if MASKS_DIR else None\n",
        "\n",
        "# Show ALL alignments: 2 cases × 6 cropped slices each, every slice with mask contour overlay (same [y,x], no .T)\n",
        "N_SLICES_PER_CASE = 6\n",
        "if masks_dir and masks_dir.exists() and df is not None and not df.empty and sitk:\n",
        "    cases_to_show = []\n",
        "    for _, row in df.head(40).iterrows():\n",
        "        cid, f = str(row[\"image_id\"]), int(row[\"fold\"])\n",
        "        root = fold_to_root[f]\n",
        "        tr = root / f\"nnUNet_raw_data_fold{f}\" / f\"Task2201_picai_fold{f}\" / \"imagesTr\"\n",
        "        if (tr / f\"{cid}_0000.nii.gz\").exists() and (masks_dir / f\"{cid}.nii.gz\").exists():\n",
        "            cases_to_show.append((cid, f))\n",
        "            if len(cases_to_show) >= 2:\n",
        "                break\n",
        "    if not cases_to_show:\n",
        "        print(\"No case with both preprocessed data and mask found.\")\n",
        "    else:\n",
        "        n_cases = len(cases_to_show)\n",
        "        n_cols = N_SLICES_PER_CASE\n",
        "        fig, axes = plt.subplots(n_cases, n_cols, figsize=(2.5 * n_cols, 2.5 * n_cases))\n",
        "        if n_cases == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "        for row_idx, (cid, f) in enumerate(cases_to_show):\n",
        "            root = fold_to_root[f]\n",
        "            tr = root / f\"nnUNet_raw_data_fold{f}\" / f\"Task2201_picai_fold{f}\" / \"imagesTr\"\n",
        "            ref = sitk.ReadImage(str(tr / f\"{cid}_0000.nii.gz\"))\n",
        "            t2w_full = _load_nii(tr / f\"{cid}_0000.nii.gz\")\n",
        "            mask_arr = resample_mask_to_ref(masks_dir / f\"{cid}.nii.gz\", ref)\n",
        "            box = bbox_3d(mask_arr, margin=CROP_MARGIN)\n",
        "            if box is None:\n",
        "                continue\n",
        "            (zmin, zmax), (ymin, ymax), (xmin, xmax) = box\n",
        "            t2w_crop = t2w_full[zmin:zmax, ymin:ymax, xmin:xmax]\n",
        "            mask_crop = mask_arr[zmin:zmax, ymin:ymax, xmin:xmax]\n",
        "            Dc, Hc, Wc = t2w_crop.shape\n",
        "            indices = [int(round(i * (Dc - 1) / (n_cols - 1))) for i in range(n_cols)] if Dc > 1 else [0] * n_cols\n",
        "            indices = [min(z, Dc - 1) for z in indices]\n",
        "            x_1d = np.arange(Wc)\n",
        "            y_1d = np.arange(Hc)\n",
        "            for col_idx, zi in enumerate(indices):\n",
        "                sl = t2w_crop[zi]\n",
        "                mask_sl = mask_crop[zi]\n",
        "                ax = axes[row_idx, col_idx]\n",
        "                ax.imshow(sl, cmap=\"gray\", origin=\"lower\", extent=[0, Wc, 0, Hc], aspect=\"equal\")\n",
        "                ax.contour(x_1d, y_1d, mask_sl, levels=[0.5], colors=\"lime\", linewidths=1.5)\n",
        "                ax.set_title(f\"{cid} z={zi}\")\n",
        "                ax.set_axis_off()\n",
        "        plt.suptitle(\"All alignments: cropped slice + mask contour (same [y,x], no .T) — verify green outline on prostate\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"Set MASKS_DIR and run paths cell to show alignments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Before/after prostate crop (run after paths cell; set MASKS_DIR to use)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import SimpleITK as sitk\n",
        "except ImportError:\n",
        "    sitk = None\n",
        "\n",
        "def _load_nii(path):\n",
        "    if sitk:\n",
        "        return np.asarray(sitk.GetArrayFromImage(sitk.ReadImage(str(path))), dtype=np.float32)\n",
        "    import nibabel as nib\n",
        "    a = nib.load(str(path)).get_fdata()\n",
        "    return np.transpose(a, (2, 0, 1)).astype(np.float32)\n",
        "\n",
        "def resample_mask_to_ref(mask_path, ref_sitk):\n",
        "    mask = sitk.ReadImage(str(mask_path))\n",
        "    res = sitk.Resample(mask, ref_sitk, sitk.Transform(3, sitk.sitkIdentity), sitk.sitkNearestNeighbor, 0.0)\n",
        "    return np.asarray(sitk.GetArrayFromImage(res))\n",
        "\n",
        "def bbox_3d(mask, margin=0):\n",
        "    inds = np.where(mask > 0)\n",
        "    if len(inds[0]) == 0:\n",
        "        return None\n",
        "    zmin, zmax = inds[0].min() - margin, inds[0].max() + 1 + margin\n",
        "    ymin, ymax = inds[1].min() - margin, inds[1].max() + 1 + margin\n",
        "    xmin, xmax = inds[2].min() - margin, inds[2].max() + 1 + margin\n",
        "    zmin, ymin, xmin = max(0, zmin), max(0, ymin), max(0, xmin)\n",
        "    zmax = min(mask.shape[0], zmax)\n",
        "    ymax = min(mask.shape[1], ymax)\n",
        "    xmax = min(mask.shape[2], xmax)\n",
        "    return (zmin, zmax), (ymin, ymax), (xmin, xmax)\n",
        "\n",
        "masks_dir = Path(MASKS_DIR) if MASKS_DIR else None\n",
        "if masks_dir is None or not masks_dir.exists():\n",
        "    print(\"Set MASKS_DIR to the prostate whole-gland masks folder (e.g. picai_labels/.../Bosma22b) to visualize crop.\")\n",
        "elif df is None or df.empty:\n",
        "    print(\"Run the paths cell first so df is built (case list and labels).\")\n",
        "else:\n",
        "    case_id, fold = None, None\n",
        "    for _, row in df.head(30).iterrows():\n",
        "        cid, f = str(row[\"image_id\"]), int(row[\"fold\"])\n",
        "        root = fold_to_root[f]\n",
        "        tr = root / f\"nnUNet_raw_data_fold{f}\" / f\"Task2201_picai_fold{f}\" / \"imagesTr\"\n",
        "        mask_path = masks_dir / f\"{cid}.nii.gz\"\n",
        "        if (tr / f\"{cid}_0000.nii.gz\").exists() and mask_path.exists():\n",
        "            case_id, fold = cid, f\n",
        "            break\n",
        "    if case_id is None:\n",
        "        print(\"No case found with both preprocessed data and mask.\")\n",
        "    else:\n",
        "        root = fold_to_root[fold]\n",
        "        tr = root / f\"nnUNet_raw_data_fold{fold}\" / f\"Task2201_picai_fold{fold}\" / \"imagesTr\"\n",
        "        ref = sitk.ReadImage(str(tr / f\"{case_id}_0000.nii.gz\"))\n",
        "        t2w_full = _load_nii(tr / f\"{case_id}_0000.nii.gz\")\n",
        "        mask_arr = resample_mask_to_ref(masks_dir / f\"{case_id}.nii.gz\", ref)\n",
        "        box = bbox_3d(mask_arr, margin=CROP_MARGIN)\n",
        "        if box is None:\n",
        "            print(\"Empty mask; cannot show crop.\")\n",
        "        else:\n",
        "            (zmin, zmax), (ymin, ymax), (xmin, xmax) = box\n",
        "            t2w_crop = t2w_full[zmin:zmax, ymin:ymax, xmin:xmax]\n",
        "            D, H, W = t2w_full.shape\n",
        "            Dc, Hc, Wc = t2w_crop.shape\n",
        "            # Show 3 slices: before (full + bbox + mask contour), after (crop), mask\n",
        "            indices_full = [max(0, D//2 - 1), D//2, min(D-1, D//2 + 1)]\n",
        "            fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
        "            for col, zi in enumerate(indices_full):\n",
        "                sl_full = t2w_full[zi]\n",
        "                mask_sl = mask_arr[zi]\n",
        "                ax_before = axes[0, col]\n",
        "                # Image and contour: sl_full, mask_sl are (H, W) with [y,x]. Extent [0,W,0,H] = (x,y); no .T so they align.\n",
        "                ax_before.imshow(sl_full, cmap=\"gray\", origin=\"lower\", extent=[0, W, 0, H], aspect=\"equal\")\n",
        "                x_1d = np.arange(W)\n",
        "                y_1d = np.arange(H)\n",
        "                ax_before.contour(x_1d, y_1d, mask_sl, levels=[0.5], colors=\"lime\", linewidths=1.5)\n",
        "                rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, edgecolor=\"cyan\", linewidth=2)\n",
        "                ax_before.add_patch(rect)\n",
        "                ax_before.set_title(f\"Before (slice {zi})\")\n",
        "                ax_before.set_axis_off()\n",
        "                z_crop = zi - zmin\n",
        "                if 0 <= z_crop < Dc:\n",
        "                    sl_crop = t2w_crop[z_crop]\n",
        "                    axes[1, col].imshow(sl_crop, cmap=\"gray\", origin=\"lower\", extent=[0, Wc, 0, Hc], aspect=\"equal\")\n",
        "                axes[1, col].set_title(f\"After crop (slice {zi})\" if 0 <= z_crop < Dc else \"After (n/a)\")\n",
        "                axes[1, col].set_axis_off()\n",
        "                axes[2, col].imshow(mask_sl, cmap=\"Greens\", origin=\"lower\", extent=[0, W, 0, H], aspect=\"equal\", vmin=0, vmax=1)\n",
        "                axes[2, col].set_title(f\"Mask (slice {zi})\")\n",
        "                axes[2, col].set_axis_off()\n",
        "            axes[0, 0].set_ylabel(\"Before (full)\", fontsize=11)\n",
        "            axes[1, 0].set_ylabel(\"After (ROI)\", fontsize=11)\n",
        "            axes[2, 0].set_ylabel(\"Mask\", fontsize=11)\n",
        "            plt.suptitle(f\"Case {case_id} — prostate crop (box: z=[{zmin}:{zmax}] y=[{ymin}:{ymax}] x=[{xmin}:{xmax}])\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Write the extractor script to disk so the next cell can run it (skip this cell if you already uploaded offline_feature_extraction_picai.py)\n",
        "_SCRIPT = r'''\n",
        "\"\"\"Offline FPN feature extraction for PI-CAI (backbone + FPN top-down/lateral).\"\"\"\n",
        "import argparse, sys\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "try:\n",
        "    import SimpleITK as sitk\n",
        "    HAS_SITK = True\n",
        "except ImportError:\n",
        "    HAS_SITK = False\n",
        "\n",
        "class FeaturePyramidNetwork(nn.Module):\n",
        "    def __init__(self, in_channels_list, out_channels, top_down_pathway=True, upsample_method=\"nearest\"):\n",
        "        super().__init__()\n",
        "        self.top_down_pathway = top_down_pathway\n",
        "        self.upsample_method = upsample_method\n",
        "        self.inner_blocks = nn.ModuleDict({\n",
        "            f\"inner_block_{idx}\": nn.Conv2d(in_ch, out_channels, kernel_size=1, bias=True)\n",
        "            for idx, in_ch in enumerate(in_channels_list)\n",
        "        })\n",
        "        self.layer_blocks = nn.ModuleDict({\n",
        "            f\"layer_block_{idx}\": nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=True)\n",
        "            for idx in range(len(in_channels_list))\n",
        "        })\n",
        "    def forward(self, selected_fmaps):\n",
        "        last_inner = self.inner_blocks[\"inner_block_1\"](selected_fmaps[-1])\n",
        "        results = [self.layer_blocks[\"layer_block_1\"](last_inner)]\n",
        "        if self.top_down_pathway:\n",
        "            inner_lateral = self.inner_blocks[\"inner_block_0\"](selected_fmaps[0])\n",
        "            feat_shape = inner_lateral.shape[-2:]\n",
        "            inner_top_down = F.interpolate(last_inner, size=feat_shape, mode=self.upsample_method)\n",
        "            last_inner = inner_lateral + inner_top_down\n",
        "            results.insert(0, self.layer_blocks[\"layer_block_0\"](last_inner))\n",
        "        else:\n",
        "            inner_lateral = self.inner_blocks[\"inner_block_0\"](selected_fmaps[0])\n",
        "            results.insert(0, self.layer_blocks[\"layer_block_0\"](inner_lateral))\n",
        "        results.append(F.max_pool2d(results[-1], kernel_size=1, stride=4, padding=0))\n",
        "        return OrderedDict([(f\"feat_{i}\", fmap) for i, fmap in enumerate(results)])\n",
        "\n",
        "def get_backbone_and_fpn(out_dim=256):\n",
        "    from torchvision.models import resnet18\n",
        "    resnet = resnet18(weights=None)\n",
        "    class Backbone(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.conv1, self.bn1, self.relu = resnet.conv1, resnet.bn1, resnet.relu\n",
        "            self.maxpool, self.layer1, self.layer2 = resnet.maxpool, resnet.layer1, resnet.layer2\n",
        "            self.layer3, self.layer4 = resnet.layer3, resnet.layer4\n",
        "        def forward(self, x):\n",
        "            x = self.relu(self.bn1(self.conv1(x)))\n",
        "            x = self.maxpool(x)\n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "            f1 = self.layer3(x)\n",
        "            f2 = self.layer4(f1)\n",
        "            return [f1, f2]\n",
        "    backbone = Backbone()\n",
        "    fpn = FeaturePyramidNetwork(in_channels_list=[256, 512], out_channels=out_dim, top_down_pathway=True)\n",
        "    class Encoder(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.backbone = backbone\n",
        "            self.fpn = fpn\n",
        "        def forward(self, x):\n",
        "            fmaps = self.backbone(x)\n",
        "            refined = self.fpn(fmaps)\n",
        "            return refined[\"feat_0\"], refined[\"feat_1\"]\n",
        "    return Encoder()\n",
        "\n",
        "def _load(path):\n",
        "    if HAS_SITK:\n",
        "        return np.asarray(sitk.GetArrayFromImage(sitk.ReadImage(str(path))), dtype=np.float32)\n",
        "    import nibabel as nib\n",
        "    a = nib.load(str(path)).get_fdata()\n",
        "    return np.transpose(a, (2,0,1)).astype(np.float32)\n",
        "\n",
        "def load_preprocessed(root, case_id, fold):\n",
        "    tr = root / f\"nnUNet_raw_data_fold{fold}\" / f\"Task2201_picai_fold{fold}\" / \"imagesTr\"\n",
        "    return np.stack([_load(tr/f\"{case_id}_0000.nii.gz\"), _load(tr/f\"{case_id}_0001.nii.gz\"), _load(tr/f\"{case_id}_0002.nii.gz\")], axis=0)\n",
        "\n",
        "def resample_mask_to_ref(mask_path, ref_sitk):\n",
        "    mask = sitk.ReadImage(str(mask_path))\n",
        "    res = sitk.Resample(mask, ref_sitk, sitk.Transform(3, sitk.sitkIdentity), sitk.sitkNearestNeighbor, 0.0)\n",
        "    return np.asarray(sitk.GetArrayFromImage(res))\n",
        "\n",
        "def bbox_3d(mask, margin=0):\n",
        "    inds = np.where(mask > 0)\n",
        "    if len(inds[0]) == 0: return None\n",
        "    zmin, zmax = inds[0].min() - margin, inds[0].max() + 1 + margin\n",
        "    ymin, ymax = inds[1].min() - margin, inds[1].max() + 1 + margin\n",
        "    xmin, xmax = inds[2].min() - margin, inds[2].max() + 1 + margin\n",
        "    zmin, ymin, xmin = max(0, zmin), max(0, ymin), max(0, xmin)\n",
        "    zmax = min(mask.shape[0], zmax)\n",
        "    ymax = min(mask.shape[1], ymax)\n",
        "    xmax = min(mask.shape[2], xmax)\n",
        "    return (zmin, zmax), (ymin, ymax), (xmin, xmax)\n",
        "\n",
        "def crop_vol_to_roi(vol, masks_dir, case_id, ref_path, margin=2):\n",
        "    masks_dir = Path(masks_dir)\n",
        "    mask_path = masks_dir / f\"{case_id}.nii.gz\"\n",
        "    if not mask_path.exists():\n",
        "        return vol, None\n",
        "    ref = sitk.ReadImage(str(ref_path))\n",
        "    mask_arr = resample_mask_to_ref(mask_path, ref)\n",
        "    box = bbox_3d(mask_arr, margin=margin)\n",
        "    if box is None: return vol, None\n",
        "    (zmin, zmax), (ymin, ymax), (xmin, xmax) = box\n",
        "    vol = vol[:, zmin:zmax, ymin:ymax, xmin:xmax].copy()\n",
        "    return vol, np.array([zmin, zmax, ymin, ymax, xmin, xmax], dtype=np.int32)\n",
        "\n",
        "def extract(vol, patch_size=224):\n",
        "    \"\"\"Extract one 224x224 patch per slice: each slice is resized/padded to patch_size x patch_size.\"\"\"\n",
        "    c, d, h, w = vol.shape\n",
        "    out, coords = [], []\n",
        "    for z in range(d):\n",
        "        sl = vol[:, z, :, :]\n",
        "        if sl.shape[1] < patch_size or sl.shape[2] < patch_size:\n",
        "            sl = np.pad(sl, ((0,0),(0,max(0,patch_size-sl.shape[1])),(0,max(0,patch_size-sl.shape[2]))), mode=\"constant\", constant_values=0)\n",
        "        if sl.shape[1] > patch_size or sl.shape[2] > patch_size:\n",
        "            t = torch.nn.functional.interpolate(torch.from_numpy(sl).unsqueeze(0).float(), (patch_size, patch_size), mode=\"bilinear\", align_corners=False)\n",
        "            sl = t.squeeze(0).numpy()\n",
        "        out.append(sl)\n",
        "        coords.append([z, 0, 0])\n",
        "    return np.stack(out).astype(np.float32), np.array(coords, dtype=np.float32)\n",
        "\n",
        "def main(argv=None):\n",
        "    argv = argv or sys.argv[1:]\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--source\", default=\"preprocessed\")\n",
        "    p.add_argument(\"--preprocessed_root\", default=None)\n",
        "    p.add_argument(\"--labels_csv\", default=None)\n",
        "    p.add_argument(\"--feat_dir\", default=\"picai_extracted_features\")\n",
        "    p.add_argument(\"--patch_size\", type=int, default=224)\n",
        "    p.add_argument(\"--feat_dim\", type=int, default=256)\n",
        "    p.add_argument(\"--device\", default=\"cuda\")\n",
        "    p.add_argument(\"--batch_slices\", type=int, default=32)\n",
        "    p.add_argument(\"--stride\", type=int, default=224, help=\"Stride for patch grid (224=no overlap, 112=50%% overlap)\")\n",
        "    p.add_argument(\"--masks_dir\", default=None, help=\"Prostate whole-gland masks (picai_labels/Bosma22b); crop to ROI before extraction\")\n",
        "    p.add_argument(\"--crop_margin\", type=int, default=2)\n",
        "    args = p.parse_args(argv)\n",
        "    if not args.labels_csv or not args.preprocessed_root:\n",
        "        raise ValueError(\"Need --labels_csv and --preprocessed_root\")\n",
        "    if not HAS_SITK:\n",
        "        raise ImportError(\"pip install SimpleITK\")\n",
        "    import pandas as pd\n",
        "    import h5py\n",
        "    df = pd.read_csv(args.labels_csv)\n",
        "    if \"image_id\" not in df.columns:\n",
        "        df[\"image_id\"] = df[\"patient_id\"]\n",
        "    root_col = \"preprocessed_root\" if \"preprocessed_root\" in df.columns else None\n",
        "    feat_dir = Path(args.feat_dir)\n",
        "    device = torch.device(args.device if torch.cuda.is_available() else \"cpu\")\n",
        "    encoder = get_backbone_and_fpn(args.feat_dim).to(device).eval()\n",
        "    for _, row in df.iterrows():\n",
        "        case_id, fold = str(row[\"image_id\"]), int(row[\"fold\"])\n",
        "        root = Path(row[root_col]) if root_col else Path(args.preprocessed_root)\n",
        "        tr = root / f\"nnUNet_raw_data_fold{fold}\" / f\"Task2201_picai_fold{fold}\" / \"imagesTr\"\n",
        "        if not (tr / f\"{case_id}_0000.nii.gz\").exists():\n",
        "            print(\"Skip\", case_id)\n",
        "            continue\n",
        "        out_bag = feat_dir / \"multi_scale\" / case_id / case_id\n",
        "        out_bag.mkdir(parents=True, exist_ok=True)\n",
        "        if (out_bag / \"C4_patch_features.pt\").exists():\n",
        "            print(\"Exists\", case_id)\n",
        "            continue\n",
        "        try:\n",
        "            vol = load_preprocessed(root, case_id, fold)\n",
        "        except Exception as e:\n",
        "            print(\"Load failed\", case_id, e)\n",
        "            continue\n",
        "        roi_bbox = None\n",
        "        if args.masks_dir:\n",
        "            ref_path = tr / f\"{case_id}_0000.nii.gz\"\n",
        "            vol, roi_bbox = crop_vol_to_roi(vol, args.masks_dir, case_id, ref_path, margin=args.crop_margin)\n",
        "            if roi_bbox is not None:\n",
        "                print(\"  Cropped to ROI\", vol.shape)\n",
        "        X, coords = extract(vol, args.patch_size)\n",
        "        X = (X - X.mean()) / (X.std() + 1e-5)\n",
        "        X = torch.from_numpy(X).float().to(device)\n",
        "        c4l, c5l = [], []\n",
        "        for i in range(0, len(X), args.batch_slices):\n",
        "            with torch.no_grad():\n",
        "                c4, c5 = encoder(X[i:i+args.batch_slices])\n",
        "            c4l.append(c4.cpu())\n",
        "            c5l.append(c5.cpu())\n",
        "        C4, C5 = torch.cat(c4l), torch.cat(c5l)\n",
        "        torch.save(C4, out_bag / \"C4_patch_features.pt\")\n",
        "        torch.save(C5, out_bag / \"C5_patch_features.pt\")\n",
        "        with h5py.File(out_bag / \"info_patches.h5\", \"w\") as f:\n",
        "            f.create_dataset(\"coords\", data=coords)\n",
        "            f.attrs[\"patch_size\"] = args.patch_size\n",
        "            f.attrs[\"extract_mode\"] = \"one_patch_per_slice\"\n",
        "            f.attrs[\"img_height\"], f.attrs[\"img_width\"] = vol.shape[2], vol.shape[3]\n",
        "            if roi_bbox is not None:\n",
        "                f.create_dataset(\"roi_bbox\", data=roi_bbox)\n",
        "        print(\"Saved\", case_id, C4.shape[0], \"slices\")\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "Path(\"/kaggle/working/offline_feature_extraction_picai.py\").write_text(_SCRIPT.strip())\n",
        "print(\"Script written to /kaggle/working/offline_feature_extraction_picai.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Run offline feature extraction\n",
        "# Input: use CROPPED_ROOT if you ran \"Batch crop all cases\"; else per-row preprocessed_root from CSV (all 5 folds).\n",
        "# Output: one patch per slice (T2W+ADC+HBV), one bag per case → multi_scale/<case_id>/<case_id>/ C4, C5, info_patches.h5\n",
        "import sys\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "use_cropped = Path(CROPPED_ROOT).exists() and any(\n",
        "    (Path(CROPPED_ROOT) / f\"nnUNet_raw_data_fold{f}\").exists() for f in FOLDS\n",
        ")\n",
        "preprocessed_root = CROPPED_ROOT if use_cropped else str(fold_to_root[FOLDS[0]])\n",
        "labels_csv = LABELS_CSV_PATH\n",
        "if use_cropped:\n",
        "    # Script must read all cases from CROPPED_ROOT; CSV has per-row roots, so override.\n",
        "    df_run = pd.read_csv(LABELS_CSV_PATH)\n",
        "    df_run[\"preprocessed_root\"] = CROPPED_ROOT\n",
        "    labels_csv = \"/kaggle/working/picai_labels_run.csv\"\n",
        "    df_run.to_csv(labels_csv, index=False)\n",
        "    print(\"Using single root for all folds (cropped):\", CROPPED_ROOT)\n",
        "cmd = [\n",
        "    sys.executable, \"/kaggle/working/offline_feature_extraction_picai.py\",\n",
        "    \"--source\", \"preprocessed\",\n",
        "    \"--preprocessed_root\", preprocessed_root,\n",
        "    \"--labels_csv\", labels_csv,\n",
        "    \"--feat_dir\", FEAT_DIR,\n",
        "    \"--device\", \"cuda\",\n",
        "    \"--stride\", \"224\",   # 224 = no overlap; use 112 for 50% overlap (more patches)\n",
        "]\n",
        "if not use_cropped and MASKS_DIR:\n",
        "    cmd += [\"--masks_dir\", str(MASKS_DIR), \"--crop_margin\", str(CROP_MARGIN)]\n",
        "if not use_cropped:\n",
        "    print(\"Using per-row preprocessed_root from CSV (folds\", FOLDS, \"). Extractor will use root for each case from CSV.\")\n",
        "subprocess.run(cmd, check=True)\n",
        "print(\"Features saved under\", FEAT_DIR)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 11071316,
          "datasetId": 6427300,
          "sourceId": 10721816,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 298366144,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
